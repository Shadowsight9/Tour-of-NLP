{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fef4a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9e15cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import sys\n",
    "drive.mount('/content/drive')\n",
    "#设置路径\n",
    "sys.path.append('/content/drive/MyDrive/Colab Notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb14c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers==4.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ecf1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install  torch==1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365865c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torchvision==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5924d70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install numpy==1.17.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccccd71",
   "metadata": {},
   "source": [
    "## logging\n",
    "Transformers 有一个集中的日志记录系统，因此您可以轻松设置库的详细程度。\n",
    "目前该库的默认详细程度是WARNING.\n",
    "* transformers.logging.CRITICALor transformers.logging.FATAL(int value, 50)：只报告最严重的错误。\n",
    "* transformers.logging.ERROR(int value, 40)：只报告错误。\n",
    "* transformers.logging.WARNINGor transformers.logging.WARN(int value, 30)：只报告错误和警告。这是库使用的默认级别。\n",
    "* transformers.logging.INFO(int value, 20)：报告错误、警告和基本信息。\n",
    "* transformers.logging.DEBUG(int value, 10)：上报所有信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef63b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from transformer import logging\n",
    "from transformers import BertTokenizer\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "def seed_everything(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "  return seed\n",
    "\n",
    "logging.set_verbosity_info()\n",
    "seed_everything(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8099e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = '/content/drive/MyDrive/Colab Notebooks/dataset/ESIM'\n",
    "model_path = '/content/drive/MyDrive/Colab Notebooks/dataset/BERT_model'\n",
    "output_dir = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7183f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796b487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(path, data_type='train'):\n",
    "  sentence_a = []\n",
    "  sentence_b = []\n",
    "  labels = []\n",
    "\n",
    "  with open(path, 'r', encoding = 'utf8') as f:\n",
    "    for line in tqdm(f.readlines(), desc=f'Reading {data_type} data'):\n",
    "      line = json.loads(line)\n",
    "      sentence_a.append(line['sentence1'])\n",
    "      sentence_b.append(line['sentence2'])\n",
    "      if data_type != 'test':\n",
    "        labels.append(int(line['label']))\n",
    "      else:\n",
    "        labels.append(0)\n",
    "\n",
    "  df = pd.DataFrame(zip(sentence_a, sentence_b, labels), columns = ['text_a', 'text_b', 'labels'])\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47951b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(config, tokenizer):\n",
    "  train_df = parse_data(os.path.join(corpus_path, 'train.json'), data_type = 'train')\n",
    "  dev_df = parse_data(os.path.join(corpus_path, 'dev.json'), data_type = 'dev')\n",
    "  test_df = parse_data(os.path.join(corpus_path, 'test.json'), data_type = 'test')\n",
    "\n",
    "  train_df.append(dev_df)\n",
    "  train_df.append(test_df)\n",
    "  inputs = defaultdict(list)\n",
    "\n",
    "\n",
    "  for i, row in tqdm(train_df.iterrows(), desc= f'Preprocessing train data', total = len(train_df)):\n",
    "      inputs_dict = tokenizer.encode_plus(row[0] + row[1], add_special_tokens = True,\n",
    "                                          return_token_type_ids = True, return_attention_mask = True)\n",
    "      inputs['input_ids'].append(inputs_dict['input_ids'])\n",
    "      inputs['token_type_ids'].append(inputs_dict['token_type_ids'])\n",
    "      inputs['attention_mask'].append(inputs_dict['attention_mask'])\n",
    "    \n",
    "    \n",
    "    \n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc2b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data(corpus_path, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
