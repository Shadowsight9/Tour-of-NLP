{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_self_AFQMC_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dVXLkF-4_zR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e96320-8668-4c83-ccd6-ac4030cfc19b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr 27 11:32:57 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8    29W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "#设置路径\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks')"
      ],
      "metadata": {
        "id": "9KtM0UMx_8TA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "857e2b0e-e99f-48bc-c2f1-2bb822ad09df"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers==4.0.1"
      ],
      "metadata": {
        "id": "VE9Fr9z4_-l4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8593c3f7-b0b2-4fd8-d754-5116cafdd7b4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.0.1 in /usr/local/lib/python3.7/dist-packages (4.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (0.0.49)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (3.6.0)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (0.9.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (4.64.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.0.1) (3.0.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch版本为1.6\n",
        "! pip install torch==1.6.0"
      ],
      "metadata": {
        "id": "CGn36OdbAAN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c1fcbbc-4bf5-492c-c7fc-c39d6707aa60"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.7/dist-packages (1.6.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torchvision 是PyTorch中专门用来处理图像的库\n",
        "! pip install torchvision==0.7.0"
      ],
      "metadata": {
        "id": "k4GiZN9pAHqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "279f48f8-2702-4651-aa1a-d85c183e8b19"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision==0.7.0 in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (7.1.2)\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (1.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (1.21.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->torchvision==0.7.0) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "config = {\n",
        "    'train_file_path':'/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/train.json',\n",
        "    'dev_file_path':'/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/dev.json',\n",
        "    'test_file_path':'/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/test.json',\n",
        "    'model_path':'/content/drive/MyDrive/Colab Notebooks/dataset/BERT_model',\n",
        "    'output_path': '.',\n",
        "    'train_val_ratio':0.1,\n",
        "    'vocab_size':30000,\n",
        "    'batch_size':64,\n",
        "    'max_seq_len':64,\n",
        "    'num_epochs':1,\n",
        "    'learning_rate':2e-5,\n",
        "    'eps': 0.1,\n",
        "    'alpha': 0.3,\n",
        "    'adv': 'fgm',\n",
        "    'warmup_ratio': 0.05,\n",
        "    'weight_decay': 0.01,\n",
        "    'use_bucket': True,\n",
        "    'bucket_multiplier': 200,\n",
        "    'n_gpus': 0,\n",
        "    'use_amp': True, # 只针对有 tensor core 的gpu有效\n",
        "    'ema_start_step': 500,\n",
        "    'ema_start': False,\n",
        "    'logging_step':100,\n",
        "    'seed':2022\n",
        "}\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "  config['device'] = 'cpu'\n",
        "else:\n",
        "  config['n_gpus'] = torch.cuda.device_count()\n",
        "  config['batch_size'] *= config['n_gpus']\n",
        "\n",
        "if not os.path.exists(config['output_path']):\n",
        "    os.makedirs((config['output_path']))\n",
        "\n",
        "    \n",
        "def seed_everything(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  return seed\n",
        "\n",
        "seed_everything(config['seed'])"
      ],
      "metadata": {
        "id": "wf9S2cB1ASJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bde25b95-6714-4493-8c3b-b3e90448d8f3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2022"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_data(path, data_type='train'):\n",
        "  sentence_a = []\n",
        "  sentence_b = []\n",
        "  labels = []\n",
        "\n",
        "  with open(path, 'r', encoding = 'utf8') as f:\n",
        "    for line in tqdm(f.readlines(), desc=f'Reading {data_type} data'):\n",
        "      line = json.loads(line)\n",
        "      sentence_a.append(line['sentence1'])\n",
        "      sentence_b.append(line['sentence2'])\n",
        "      if data_type != 'test':\n",
        "        labels.append(int(line['label']))\n",
        "      else:\n",
        "        labels.append(0)\n",
        "\n",
        "  df = pd.DataFrame(zip(sentence_a, sentence_b, labels), columns = ['text_a', 'text_b', 'labels'])\n",
        "  return df"
      ],
      "metadata": {
        "id": "uI_qfoiepHf-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## encode和encode_plus的区别\n",
        "1. encode仅返回input_ids\n",
        "2. encode_plus返回所有的编码信息，具体如下：\n",
        "’input_ids:是单词在词典中的编码; \n",
        "‘token_type_ids’:区分两个句子的编码（上句全为0，下句全为1）; \n",
        "‘attention_mask’:指定对哪些词进行self-Attention操作\n",
        "\n",
        "```\n",
        "model_name = 'bert-base-uncased'\n",
        "\n",
        "# a.通过词典导入分词器\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "sentence = \"Hello, my son is laughing.\"\n",
        "\n",
        "print(tokenizer.encode(sentence))\n",
        "print(tokenizer.encode_plus(sentence))\n",
        "\n",
        "\n",
        "运行结果：\n",
        "\n",
        "[101, 7592, 1010, 2026, 2365, 2003, 5870, 1012, 102]\n",
        "{'input_ids': [101, 7592, 1010, 2026, 2365, 2003, 5870, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
        "```"
      ],
      "metadata": {
        "id": "TBd0MFciyFAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs: defaultdict(list)\n",
        "def build_bert_inputs(inputs, label, sentence_a, sentence_b, tokenizer):\n",
        "  # add_special_tokens [CLS] [SEP]\n",
        "  # return_token_type_ids 该词属于sentence_a(返回0) or sentence_b(返回1). \n",
        "  # return_attention_mask pad=0, 不是pad的部分标为1， 是pad标为0.\n",
        "  inputs_dict = tokenizer.encode_plus(sentence_a, sentence_b, add_special_tokens = True,\n",
        "                     return_token_type_ids = True,\n",
        "                     return_attention_mask = True)\n",
        "  inputs['input_ids'].append(inputs_dict['input_ids'])\n",
        "  inputs['token_type_ids'].append(inputs_dict['token_type_ids'])\n",
        "  inputs['attention_mask'].append(inputs_dict['attention_mask'])\n",
        "  inputs['labels'].append(label)"
      ],
      "metadata": {
        "id": "MpNesXYtvHhB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## defaultdict(list)\n",
        "```\n",
        "from collections import defaultdict\n",
        "result = defaultdict(list)\n",
        "data = [(\"p\", 1), (\"p\", 2), (\"p\", 3),\n",
        "     (\"h\", 1), (\"h\", 2), (\"h\", 3)]\n",
        " \n",
        "for (key, value) in data:\n",
        "    result[key].append(value)\n",
        "print(result)#defaultdict(<class 'list'>, {'p': [1, 2, 3], 'h': [1, 2, 3]})\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "MAp0Hp7L2duD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "def read_data(config, tokenizer):\n",
        "  train_df = parse_data(config['train_file_path'], data_type = 'train')\n",
        "  dev_df = parse_data(config['dev_file_path'], data_type = 'dev')\n",
        "  test_df = parse_data(config['test_file_path'], data_type = 'test')\n",
        "\n",
        "  # 把这些 df 打包成字典\n",
        "  data_df = {'train': train_df, 'dev': dev_df, 'test': test_df}\n",
        "  #保存 BERT 的输入\n",
        "  processed_data = {}\n",
        "  # 遍历字典(data_df)\n",
        "  for data_type, df in data_df.items():\n",
        "    inputs = defaultdict(list)\n",
        "    #遍历每一行\n",
        "    for i, row in tqdm(df.iterrows(), desc= f'Preprocessing {data_type} data', total = len(df)):\n",
        "      label = row[2]\n",
        "      sentence_a, sentence_b = row[0], row[1]\n",
        "      build_bert_inputs(inputs, label, sentence_a, sentence_b, tokenizer)\n",
        "\n",
        "    processed_data[data_type] = inputs\n",
        "  return processed_data"
      ],
      "metadata": {
        "id": "M5nlW7HV5IjC"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(config['model_path'])\n",
        "dt = read_data(config, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iHgufu3Hr-w",
        "outputId": "0bf0fa3a-4b2c-4496-da45-e1e6915a37d9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading train data: 100%|██████████| 34334/34334 [00:00<00:00, 144188.33it/s]\n",
            "Reading dev data: 100%|██████████| 4316/4316 [00:00<00:00, 113366.67it/s]\n",
            "Reading test data: 100%|██████████| 3861/3861 [00:00<00:00, 117546.09it/s]\n",
            "Preprocessing train data: 100%|██████████| 34334/34334 [00:36<00:00, 943.31it/s] \n",
            "Preprocessing dev data: 100%|██████████| 4316/4316 [00:03<00:00, 1412.76it/s]\n",
            "Preprocessing test data: 100%|██████████| 3861/3861 [00:03<00:00, 1238.07it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('train_df中 input_ids的第一条数据',dt['train']['input_ids'][0])\n",
        "print('dev_df中 token_type_ids的第一条数据',dt['dev']['token_type_ids'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JAghBwfII4n",
        "outputId": "2fae7e29-9ea8-466d-94ba-867b19d32fc7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_df中 input_ids的第一条数据 [101, 6010, 6009, 955, 1446, 5023, 7583, 6820, 3621, 1377, 809, 2940, 2768, 1044, 2622, 1400, 3315, 1408, 102, 955, 1446, 3300, 1044, 2622, 1168, 3309, 6820, 3315, 1408, 102]\n",
            "dev_df中 token_type_ids的第一条数据 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class AFQMCDataset(Dataset):\n",
        "  def __init__(self, data_dict):\n",
        "    super(AFQMCDataset, self).__init__()\n",
        "    self.data_dict = data_dict\n",
        "  \n",
        "  # 返回一个example\n",
        "  def __getitem__(self, idx):\n",
        "    data = (self.data_dict['input_ids'][idx],\n",
        "         self.data_dict['token_type_ids'][idx],\n",
        "         self.data_dict['attention_mask'][idx],\n",
        "         self.data_dict['labels'][idx])\n",
        "    return data\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.data_dict['input_ids'])"
      ],
      "metadata": {
        "id": "H6u3Lttbs8qx"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Collator:\n",
        "  def __init__(self, max_seq_len, tokenizer):\n",
        "    self.max_seq_len = max_seq_len\n",
        "    self.tokenizer = tokenizer\n",
        "  \n",
        "  def pad_and_truncate(self, input_ids_list, token_type_ids_list, attention_mask_list, labels_list, max_seq_len):\n",
        "    input_ids = torch.zeros((len(input_ids_list), max_seq_len),dtype=torch.long)\n",
        "    token_type_ids = torch.zeros_like(input_ids)\n",
        "    attention_mask = torch.zeros_like(input_ids)\n",
        "    \n",
        "    for i in range(len(input_ids_list)):\n",
        "      seq_len = len(input_ids_list[i])\n",
        "      if seq_len <= max_seq_len:\n",
        "        input_ids[i, :seq_len] = torch.tensor(input_ids_list[i], dtype = torch.long)\n",
        "        token_type_ids[i, :seq_len] = torch.tensor(token_type_ids_list[i], dtype = torch.long)\n",
        "        attention_mask[i, :seq_len] = torch.tensor(attention_mask_list[i], dtype = torch.long)\n",
        "      else:\n",
        "        # input_ids 最后一位放上一个特殊的token\n",
        "        input_ids[i] = torch.tensor(input_ids_list[i][:max_seq_len-1] + [self.tokenizer.sep_token_id], dtype = torch.long)\n",
        "        # token_type_ids 和 attention_mask 不需要加上特殊token\n",
        "        token_type_ids[i] = torch.tensor(token_type_ids_list[i][:max_seq_len], dtype = torch.long)\n",
        "        attention_mask[i] = torch.tensor(attention_mask_list[i][:max_seq_len], dtype = torch.long)\n",
        "    labels = torch.tensor(labels_list, dtype = torch.long)\n",
        "    return input_ids, token_type_ids, attention_mask, labels\n",
        "\n",
        "  def __call__(self, examples):\n",
        "    input_ids_list, token_type_ids_list, attention_mask_list, labels_list = list(zip(*examples))\n",
        "    cur_max_seq_len = max(len(input_id) for input_id in input_ids_list)\n",
        "    max_seq_len = min(cur_max_seq_len, self.max_seq_len)\n",
        "    \n",
        "    input_ids, token_type_ids, attention_mask, labels = self.pad_and_truncate(input_ids_list, token_type_ids_list, attention_mask_list, labels_list, max_seq_len)                     \n",
        "    \n",
        "    data_dict = {\n",
        "        'input_ids': input_ids,\n",
        "        'token_type_ids': token_type_ids,\n",
        "        'attention_mask': attention_mask,\n",
        "        'labels': labels\n",
        "    }\n",
        "    return data_dict"
      ],
      "metadata": {
        "id": "1Xf4ahXKw6PX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collate_fn = Collator(config['max_seq_len'], tokenizer)"
      ],
      "metadata": {
        "id": "4eU_XHZx6F24"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 采样（Dataloader）"
      ],
      "metadata": {
        "id": "lvgR0VQpw_SV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Dataloader](https://img-blog.csdnimg.cn/b80cee8a1c7d49b79e7b80cc81150d66.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "DSqsAdWE9Vf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampler \n",
        "所有采样器都继承自Sampler这个类\n",
        "\n",
        "每个Sampler子类都要实现iter方法【迭代数据集example索引的方法】，以及返回迭代器长度的len方法"
      ],
      "metadata": {
        "id": "QS-HVTDV9xfn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sampler](https://img-blog.csdnimg.cn/1c40aedade9f40a493b4df97d0c1def0.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "HhylX0uH9Vb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 顺序采样\n",
        "![sequentialsampler](https://img-blog.csdnimg.cn/9e8ee018cea84729ac6b5742395d8ea2.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n",
        "\n",
        "***在初始化时拿到数据集data_source， 按顺序对元素进行采样，每次只返回一个索引值 ***"
      ],
      "metadata": {
        "id": "FXjatAc6BUGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 顺序采样举例\n",
        "# randperm 把 0-23 数据打乱 形成3维tensor\n",
        "# (2,3,4) batch_size:2 seq_len=3, embedding_dim=4，每个 batch 有2条数据，每个句子包含3个词， 每个词的维度是4\n",
        "a = torch.randperm(24).reshape((2,3,4))\n",
        "print('a:',a)\n",
        "b = torch.utils.data.SequentialSampler(a)\n",
        "print('b:',b)\n",
        "# i 是索引\n",
        "for i in b:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dZh5C6acm0S",
        "outputId": "bf9b2de9-d58c-4f35-8034-361062b7562e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: tensor([[[ 5, 14,  9,  2],\n",
            "         [13, 12, 20,  1],\n",
            "         [16, 15,  7,  4]],\n",
            "\n",
            "        [[17,  0,  3, 19],\n",
            "         [10, 22,  6, 18],\n",
            "         [ 8, 23, 11, 21]]])\n",
            "b: <torch.utils.data.sampler.SequentialSampler object at 0x7fa2131abc50>\n",
            "0\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 随机采样\n",
        "replacement : True 表示可以重复采样\n",
        "\n",
        "num_samples: 指定采样的数量\n",
        "\n",
        "PS:当使用replacement=False，不应制定num_samples\n",
        "![randomsampler](https://img-blog.csdnimg.cn/9d2e2afdbe4d4df4aee3102e46054650.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "7wyFCf2CEq7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 随机采样举例\n",
        "a = torch.randperm(60).reshape((5,3,4))\n",
        "print('a:',a)\n",
        "# 随机采样3条数据\n",
        "b = torch.utils.data.RandomSampler(a, replacement=True, num_samples=3)\n",
        "print('b:',b)\n",
        "for i in b:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52NgI_URFidd",
        "outputId": "6f837d87-3da9-4a9c-aa99-18c6489f4b26"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: tensor([[[47, 36, 58, 12],\n",
            "         [49,  7, 24,  9],\n",
            "         [27, 13, 45,  0]],\n",
            "\n",
            "        [[ 3, 28, 23, 39],\n",
            "         [37, 29, 10, 59],\n",
            "         [ 4, 35, 56, 53]],\n",
            "\n",
            "        [[54, 32, 18, 42],\n",
            "         [41, 46, 30, 14],\n",
            "         [38, 22, 11,  5]],\n",
            "\n",
            "        [[48, 33, 57, 26],\n",
            "         [15, 19, 55, 16],\n",
            "         [20, 40, 31,  6]],\n",
            "\n",
            "        [[51, 17,  1, 25],\n",
            "         [34,  2, 43, 21],\n",
            "         [52, 50,  8, 44]]])\n",
            "b: <torch.utils.data.sampler.RandomSampler object at 0x7fa1855a5e90>\n",
            "3\n",
            "3\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subset随机采样\n",
        "SubsetRandomSampler： 从给定的索引列表中随机采样元素，不放回采样 \n",
        "\n",
        "indices(sequence): 索引序列\n",
        "![sunsetRandomSampler](https://img-blog.csdnimg.cn/e80f6a1bafe042f28da652dc5a2388ab.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "5BoYgZchGmqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset采样举例\n",
        "a = torch.randperm(60).reshape((5,3,4))\n",
        "print('a:',a)\n",
        "# 从索引2以后的样本中随机采样\n",
        "b = torch.utils.data.SubsetRandomSampler(indices=a[2:])\n",
        "for i in b:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDJ0vAv4HCci",
        "outputId": "39c83570-6508-4326-ebf3-40e47b33ea7f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: tensor([[[ 8, 18, 55, 16],\n",
            "         [49, 54, 14,  7],\n",
            "         [33, 37, 39,  2]],\n",
            "\n",
            "        [[45,  6, 24, 29],\n",
            "         [58, 57,  3, 47],\n",
            "         [46, 56, 26, 21]],\n",
            "\n",
            "        [[12, 25, 52, 40],\n",
            "         [ 9, 53, 10, 50],\n",
            "         [48, 59, 27, 22]],\n",
            "\n",
            "        [[ 0, 20, 34, 13],\n",
            "         [41, 32, 35, 51],\n",
            "         [15,  4, 36, 38]],\n",
            "\n",
            "        [[11, 19,  5, 43],\n",
            "         [23, 31, 44, 30],\n",
            "         [28,  1, 42, 17]]])\n",
            "tensor([[ 0, 20, 34, 13],\n",
            "        [41, 32, 35, 51],\n",
            "        [15,  4, 36, 38]])\n",
            "tensor([[12, 25, 52, 40],\n",
            "        [ 9, 53, 10, 50],\n",
            "        [48, 59, 27, 22]])\n",
            "tensor([[11, 19,  5, 43],\n",
            "        [23, 31, 44, 30],\n",
            "        [28,  1, 42, 17]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 分批采样\n",
        "sampler: 基采样器 \n",
        "\n",
        "batch_size: size of mini-batch\n",
        "\n",
        "drop_last=True, 如果一个batch的长度小于batch_size则丢弃\n",
        "![BatchSampler](https://img-blog.csdnimg.cn/8a1b2f5ae320453c9fae8ae8e0ef2080.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n",
        "\n"
      ],
      "metadata": {
        "id": "SF2c2rgKoquU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 分批采样举例\n",
        "a = torch.randperm(60).reshape((5,3,4))\n",
        "print('a:',a)\n",
        "# 要传一个基采样器torch.utils.data.RandomSampler(a)\n",
        "b = torch.utils.data.BatchSampler(torch.utils.data.RandomSampler(a), 2, drop_last=True)\n",
        "# 上面的i都是一个数；现在是batch_size的列表\n",
        "for i in b:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNi3EU11oqEc",
        "outputId": "2096ed88-4b42-46a1-d523-25fa2678632d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: tensor([[[34, 50, 28, 24],\n",
            "         [46,  0, 35, 21],\n",
            "         [51, 52, 33, 59]],\n",
            "\n",
            "        [[31,  5, 26, 42],\n",
            "         [11, 49,  8, 29],\n",
            "         [ 9, 17, 53, 36]],\n",
            "\n",
            "        [[ 1, 37, 22, 40],\n",
            "         [18, 20, 45,  7],\n",
            "         [10, 47, 19, 32]],\n",
            "\n",
            "        [[38, 14, 58,  3],\n",
            "         [13, 25, 27, 48],\n",
            "         [ 6, 44, 55, 30]],\n",
            "\n",
            "        [[56,  2, 57, 12],\n",
            "         [ 4, 23, 16, 15],\n",
            "         [43, 54, 41, 39]]])\n",
            "[3, 4]\n",
            "[1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 桶采样\n",
        "sort_key: 按XXX排序\n",
        "\n",
        "bucket_sampler: batch_size * bucket_size_multiplier 相当于 n * batch_size\n",
        "；len(sampler)最大为数据集的长度\n",
        "![BucketSampler](https://img-blog.csdnimg.cn/6413cea5dfbf4494a6b2b64504f74a97.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "66V_qSLzuZpZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![SortedSampler](https://img-blog.csdnimg.cn/64f60217df474cf1b0d7aa1c3558cc1f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "V-VMY39qxSKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![BucketSampler](https://img-blog.csdnimg.cn/d7e03938f2824f9cb8a6c3a895f5a78a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "_WX-4OucxiqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 桶采样举例\n",
        "# Dataset -> 得到‘大桶'的排序索引\n",
        "\n",
        "# 真实train中数据，前6条\n",
        "mini_dataset = {k: v[:6] for k, v in dt['train'].items()}\n",
        "mini_data = AFQMCDataset(mini_dataset)\n",
        "print(mini_data)\n",
        "# mini_data 的前6条数据的长度\n",
        "for i, d in enumerate(mini_data):\n",
        "    print(d[0]) # input_ids\n",
        "    print(len(d[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epOJ-plhx-XG",
        "outputId": "c8bf9c8f-6b23-48e8-9325-e29060d941f8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.AFQMCDataset object at 0x7fa2131b1090>\n",
            "[101, 6010, 6009, 955, 1446, 5023, 7583, 6820, 3621, 1377, 809, 2940, 2768, 1044, 2622, 1400, 3315, 1408, 102, 955, 1446, 3300, 1044, 2622, 1168, 3309, 6820, 3315, 1408, 102]\n",
            "30\n",
            "[101, 6010, 6009, 5709, 1446, 6432, 2769, 6824, 5276, 671, 3613, 102, 6010, 6009, 5709, 1446, 6824, 5276, 6121, 711, 3221, 784, 720, 102]\n",
            "24\n",
            "[101, 2376, 2769, 4692, 671, 678, 3315, 3299, 5709, 1446, 6572, 1296, 3300, 3766, 3300, 5310, 3926, 102, 678, 3299, 5709, 1446, 6572, 1296, 102]\n",
            "25\n",
            "[101, 6010, 6009, 955, 1446, 1914, 7270, 3198, 7313, 5341, 1394, 6397, 844, 671, 3613, 102, 955, 1446, 2533, 6397, 844, 1914, 719, 102]\n",
            "24\n",
            "[101, 2769, 4638, 5709, 1446, 6572, 1296, 3221, 115, 115, 115, 8024, 6820, 3621, 2582, 720, 3221, 115, 115, 115, 102, 2769, 4638, 5709, 1446, 8024, 3299, 5310, 1139, 3341, 6432, 6375, 2769, 6820, 115, 115, 115, 1039, 8024, 2769, 5632, 2346, 5050, 749, 671, 678, 6422, 5301, 1399, 1296, 2769, 2418, 6421, 6820, 115, 115, 115, 1039, 102]\n",
            "59\n",
            "[101, 6010, 6009, 955, 1446, 4638, 7583, 2428, 1377, 809, 794, 4509, 6435, 679, 102, 6010, 6009, 955, 1446, 5688, 969, 3189, 1377, 809, 955, 3621, 1408, 102]\n",
            "28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bucket_sampler import SortedSampler\n",
        "random_sampler = torch.utils.data.RandomSampler(mini_data, replacement=False)\n",
        "# print(list(random_sampler))\n",
        "# 关于dataset的随机索引 [3, 5, 4, 1, 0, 2]\n",
        "\n",
        "batch_sampler = torch.utils.data.BatchSampler(random_sampler, 4, drop_last=True)\n",
        "# [0, 5, 2, 4] 【还有[1, 3] 但是丢弃了】\n",
        "\n",
        "for samp in batch_sampler:\n",
        "    print('samp:',samp)\n",
        "    sorted_sampler = SortedSampler(samp, sort_key=lambda x:len(mini_data[x][0]))\n",
        "    print('list_sorted_sampler:',list(sorted_sampler))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Yyjconvz6TO",
        "outputId": "16c131ce-049f-418a-c82a-dfc20dbfa5ba"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "samp: [0, 4, 2, 3]\n",
            "list_sorted_sampler: [3, 2, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "[0, 5, 2, 4]分别对应mini_data中的长度[30, 28, 25, 59]\n",
        "\n",
        "[2, 1, 0, 3] \n",
        "\n",
        "2（位置2的数据len最小） -> 2 -> 25 \n",
        "\n",
        "1 -> 5 -> 28 \n",
        "\n",
        "0 -> 0 -> 30 \n",
        "\n",
        "3（位置3的数据len最大） -> 4 -> 59\n",
        "```"
      ],
      "metadata": {
        "id": "-A6oFU9B1RXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 得到‘大桶'的排序索引 -> 返回‘小桶'在‘大桶'中的位置\n",
        "c = list(torch.utils.data.BatchSampler(sorted_sampler, 2, drop_last=True))\n",
        "print(c)\n",
        "# c 把大桶 分成 batch_size大小的小桶"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az7SLVSs2idz",
        "outputId": "87503803-4985-485a-f19a-bf546c581e6f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2], [0, 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "[[2, 1], [0, 3]]\n",
        "```"
      ],
      "metadata": {
        "id": "ABvwvlmZ5_r5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in torch.utils.data.SubsetRandomSampler(c):\n",
        "    print('从给定的索引列表中随机采样元素')\n",
        "    print(batch)\n",
        "    print('所对应的原序列是什么：')\n",
        "    print([samp[i] for i in batch])\n",
        "    # 参考上面 from bucket_sampler import SortedSampler 单元格对应法则"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGcdBAPo3Za7",
        "outputId": "4334cef6-fda3-4bcf-f2a1-aec5492d85a0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "从给定的索引列表中随机采样元素\n",
            "[1, 2]\n",
            "所对应的原序列是什么：\n",
            "[4, 2]\n",
            "从给定的索引列表中随机采样元素\n",
            "[0, 3]\n",
            "所对应的原序列是什么：\n",
            "[0, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "从给定的索引列表中随机采样元素\n",
        "[2, 1]\n",
        "所对应的原序列是什么：\n",
        "[2, 5]\n",
        "从给定的索引列表中随机采样元素\n",
        "[0, 3]\n",
        "所对应的原序列是什么：\n",
        "[0, 4]\n",
        "```"
      ],
      "metadata": {
        "id": "l_W55Rvx5WxZ"
      }
    }
  ]
}