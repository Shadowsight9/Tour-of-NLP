{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_self_AFQMC_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TBd0MFciyFAR",
        "MAp0Hp7L2duD",
        "lvgR0VQpw_SV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dVXLkF-4_zR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80323fb2-c89b-423c-d505-06e02da74c38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr 30 14:09:48 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P8    33W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "#设置路径\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks')"
      ],
      "metadata": {
        "id": "9KtM0UMx_8TA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7425dc00-526e-4443-fee6-0dae389b4c28"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers==4.0.1"
      ],
      "metadata": {
        "id": "VE9Fr9z4_-l4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bab6c30a-f36f-47af-aa51-18217cdc86cd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.0.1 in /usr/local/lib/python3.7/dist-packages (4.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (0.0.49)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (0.9.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.0.1) (3.0.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch版本为1.6\n",
        "! pip install torch==1.6.0"
      ],
      "metadata": {
        "id": "CGn36OdbAAN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d5db615-27c5-4de6-8d4b-95aef89e9f61"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.7/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.21.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torchvision 是PyTorch中专门用来处理图像的库\n",
        "! pip install torchvision==0.7.0"
      ],
      "metadata": {
        "id": "k4GiZN9pAHqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb29b13f-2f68-425f-d187-b9ce0e8b53e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision==0.7.0 in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (1.21.6)\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (1.6.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (7.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->torchvision==0.7.0) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "config = {\n",
        "    'train_file_path':'/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/train.json',\n",
        "    'dev_file_path':'/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/dev.json',\n",
        "    'test_file_path':'/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/test.json',\n",
        "    'model_path':'/content/drive/MyDrive/Colab Notebooks/dataset/BERT_model',\n",
        "    'output_path': '.',\n",
        "    'train_val_ratio':0.1,\n",
        "    'vocab_size':30000,\n",
        "    'batch_size':64,\n",
        "    'max_seq_len':64,\n",
        "    'num_epochs':1,\n",
        "    'learning_rate':2e-5,\n",
        "    'eps': 0.1,\n",
        "    'alpha': 0.3,\n",
        "    'adv': 'fgm',\n",
        "    'warmup_ratio': 0.05,\n",
        "    'weight_decay': 0.01,\n",
        "    'use_bucket': True,\n",
        "    'bucket_multiplier': 200,\n",
        "    'n_gpus': 0,\n",
        "    'use_amp': True, # 只针对有 tensor core 的gpu有效\n",
        "    'ema_start_step': 500,\n",
        "    'ema_start': False,\n",
        "    'logging_step':100,\n",
        "    'device': 'cuda',\n",
        "    'seed':2022\n",
        "}\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "  config['device'] = 'cpu'\n",
        "else:\n",
        "  config['n_gpus'] = torch.cuda.device_count()\n",
        "  config['batch_size'] *= config['n_gpus']\n",
        "\n",
        "if not os.path.exists(config['output_path']):\n",
        "    os.makedirs((config['output_path']))\n",
        "\n",
        "    \n",
        "def seed_everything(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  return seed\n",
        "\n",
        "seed_everything(config['seed'])"
      ],
      "metadata": {
        "id": "wf9S2cB1ASJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec5d4715-6708-4689-c075-beb159129d48"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2022"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_data(path, data_type='train'):\n",
        "  sentence_a = []\n",
        "  sentence_b = []\n",
        "  labels = []\n",
        "\n",
        "  with open(path, 'r', encoding = 'utf8') as f:\n",
        "    for line in tqdm(f.readlines(), desc=f'Reading {data_type} data'):\n",
        "      line = json.loads(line)\n",
        "      sentence_a.append(line['sentence1'])\n",
        "      sentence_b.append(line['sentence2'])\n",
        "      if data_type != 'test':\n",
        "        labels.append(int(line['label']))\n",
        "      else:\n",
        "        labels.append(0)\n",
        "\n",
        "  df = pd.DataFrame(zip(sentence_a, sentence_b, labels), columns = ['text_a', 'text_b', 'labels'])\n",
        "  return df"
      ],
      "metadata": {
        "id": "uI_qfoiepHf-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## encode和encode_plus的区别\n",
        "1. encode仅返回input_ids\n",
        "2. encode_plus返回所有的编码信息，具体如下：\n",
        "’input_ids:是单词在词典中的编码; \n",
        "‘token_type_ids’:区分两个句子的编码（上句全为0，下句全为1）; \n",
        "‘attention_mask’:指定对哪些词进行self-Attention操作\n",
        "\n",
        "```\n",
        "model_name = 'bert-base-uncased'\n",
        "\n",
        "# a.通过词典导入分词器\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "sentence = \"Hello, my son is laughing.\"\n",
        "\n",
        "print(tokenizer.encode(sentence))\n",
        "print(tokenizer.encode_plus(sentence))\n",
        "\n",
        "\n",
        "运行结果：\n",
        "\n",
        "[101, 7592, 1010, 2026, 2365, 2003, 5870, 1012, 102]\n",
        "{'input_ids': [101, 7592, 1010, 2026, 2365, 2003, 5870, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
        "```"
      ],
      "metadata": {
        "id": "TBd0MFciyFAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs: defaultdict(list)\n",
        "def build_bert_inputs(inputs, label, sentence_a, sentence_b, tokenizer):\n",
        "  # add_special_tokens [CLS] [SEP]\n",
        "  # return_token_type_ids 该词属于sentence_a(返回0) or sentence_b(返回1). \n",
        "  # return_attention_mask pad=0, 不是pad的部分标为1， 是pad标为0.\n",
        "  inputs_dict = tokenizer.encode_plus(sentence_a, sentence_b, add_special_tokens = True,\n",
        "                     return_token_type_ids = True,\n",
        "                     return_attention_mask = True)\n",
        "  inputs['input_ids'].append(inputs_dict['input_ids'])\n",
        "  inputs['token_type_ids'].append(inputs_dict['token_type_ids'])\n",
        "  inputs['attention_mask'].append(inputs_dict['attention_mask'])\n",
        "  inputs['labels'].append(label)"
      ],
      "metadata": {
        "id": "MpNesXYtvHhB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## defaultdict(list)\n",
        "```\n",
        "from collections import defaultdict\n",
        "result = defaultdict(list)\n",
        "data = [(\"p\", 1), (\"p\", 2), (\"p\", 3),\n",
        "     (\"h\", 1), (\"h\", 2), (\"h\", 3)]\n",
        " \n",
        "for (key, value) in data:\n",
        "    result[key].append(value)\n",
        "print(result)#defaultdict(<class 'list'>, {'p': [1, 2, 3], 'h': [1, 2, 3]})\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "MAp0Hp7L2duD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "def read_data(config, tokenizer):\n",
        "  train_df = parse_data(config['train_file_path'], data_type = 'train')\n",
        "  dev_df = parse_data(config['dev_file_path'], data_type = 'dev')\n",
        "  test_df = parse_data(config['test_file_path'], data_type = 'test')\n",
        "\n",
        "  # 把这些 df 打包成字典\n",
        "  data_df = {'train': train_df, 'dev': dev_df, 'test': test_df}\n",
        "  #保存 BERT 的输入\n",
        "  processed_data = {}\n",
        "  # 遍历字典(data_df)\n",
        "  for data_type, df in data_df.items():\n",
        "    inputs = defaultdict(list)\n",
        "    #遍历每一行\n",
        "    for i, row in tqdm(df.iterrows(), desc= f'Preprocessing {data_type} data', total = len(df)):\n",
        "      label = row[2]\n",
        "      sentence_a, sentence_b = row[0], row[1]\n",
        "      build_bert_inputs(inputs, label, sentence_a, sentence_b, tokenizer)\n",
        "\n",
        "    processed_data[data_type] = inputs\n",
        "  return processed_data"
      ],
      "metadata": {
        "id": "M5nlW7HV5IjC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(config['model_path'])\n",
        "dt = read_data(config, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iHgufu3Hr-w",
        "outputId": "031faeb4-d0cf-45bf-bff5-84d7f2ce17dc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading train data: 100%|██████████| 34334/34334 [00:00<00:00, 179255.05it/s]\n",
            "Reading dev data: 100%|██████████| 4316/4316 [00:00<00:00, 110752.56it/s]\n",
            "Reading test data: 100%|██████████| 3861/3861 [00:00<00:00, 111601.07it/s]\n",
            "Preprocessing train data: 100%|██████████| 34334/34334 [00:31<00:00, 1079.31it/s]\n",
            "Preprocessing dev data: 100%|██████████| 4316/4316 [00:03<00:00, 1409.85it/s]\n",
            "Preprocessing test data: 100%|██████████| 3861/3861 [00:03<00:00, 1281.82it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('train_df中 input_ids的第一条数据',dt['train']['input_ids'][0])\n",
        "print('dev_df中 token_type_ids的第一条数据',dt['dev']['token_type_ids'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JAghBwfII4n",
        "outputId": "6623cfe3-fd3e-4b18-82f5-7c9b08352e1c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_df中 input_ids的第一条数据 [101, 6010, 6009, 955, 1446, 5023, 7583, 6820, 3621, 1377, 809, 2940, 2768, 1044, 2622, 1400, 3315, 1408, 102, 955, 1446, 3300, 1044, 2622, 1168, 3309, 6820, 3315, 1408, 102]\n",
            "dev_df中 token_type_ids的第一条数据 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class AFQMCDataset(Dataset):\n",
        "  def __init__(self, data_dict):\n",
        "    super(AFQMCDataset, self).__init__()\n",
        "    self.data_dict = data_dict\n",
        "  \n",
        "  # 返回一个example\n",
        "  def __getitem__(self, idx):\n",
        "    data = (self.data_dict['input_ids'][idx],\n",
        "         self.data_dict['token_type_ids'][idx],\n",
        "         self.data_dict['attention_mask'][idx],\n",
        "         self.data_dict['labels'][idx])\n",
        "    return data\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.data_dict['input_ids'])"
      ],
      "metadata": {
        "id": "H6u3Lttbs8qx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Collator:\n",
        "  def __init__(self, max_seq_len, tokenizer):\n",
        "    self.max_seq_len = max_seq_len\n",
        "    self.tokenizer = tokenizer\n",
        "  \n",
        "  def pad_and_truncate(self, input_ids_list, token_type_ids_list, attention_mask_list, labels_list, max_seq_len):\n",
        "    input_ids = torch.zeros((len(input_ids_list), max_seq_len),dtype=torch.long)\n",
        "    token_type_ids = torch.zeros_like(input_ids)\n",
        "    attention_mask = torch.zeros_like(input_ids)\n",
        "    \n",
        "    for i in range(len(input_ids_list)):\n",
        "      seq_len = len(input_ids_list[i])\n",
        "      if seq_len <= max_seq_len:\n",
        "        input_ids[i, :seq_len] = torch.tensor(input_ids_list[i], dtype = torch.long)\n",
        "        token_type_ids[i, :seq_len] = torch.tensor(token_type_ids_list[i], dtype = torch.long)\n",
        "        attention_mask[i, :seq_len] = torch.tensor(attention_mask_list[i], dtype = torch.long)\n",
        "      else:\n",
        "        # input_ids 最后一位放上一个特殊的token\n",
        "        input_ids[i] = torch.tensor(input_ids_list[i][:max_seq_len-1] + [self.tokenizer.sep_token_id], dtype = torch.long)\n",
        "        # token_type_ids 和 attention_mask 不需要加上特殊token\n",
        "        token_type_ids[i] = torch.tensor(token_type_ids_list[i][:max_seq_len], dtype = torch.long)\n",
        "        attention_mask[i] = torch.tensor(attention_mask_list[i][:max_seq_len], dtype = torch.long)\n",
        "    labels = torch.tensor(labels_list, dtype = torch.long)\n",
        "    return input_ids, token_type_ids, attention_mask, labels\n",
        "\n",
        "  def __call__(self, examples):\n",
        "    input_ids_list, token_type_ids_list, attention_mask_list, labels_list = list(zip(*examples))\n",
        "    cur_max_seq_len = max(len(input_id) for input_id in input_ids_list)\n",
        "    max_seq_len = min(cur_max_seq_len, self.max_seq_len)\n",
        "    \n",
        "    input_ids, token_type_ids, attention_mask, labels = self.pad_and_truncate(input_ids_list, token_type_ids_list, attention_mask_list, labels_list, max_seq_len)                     \n",
        "    \n",
        "    data_dict = {\n",
        "        'input_ids': input_ids,\n",
        "        'token_type_ids': token_type_ids,\n",
        "        'attention_mask': attention_mask,\n",
        "        'labels': labels\n",
        "    }\n",
        "    return data_dict"
      ],
      "metadata": {
        "id": "1Xf4ahXKw6PX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collate_fn = Collator(config['max_seq_len'], tokenizer)"
      ],
      "metadata": {
        "id": "4eU_XHZx6F24"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 采样（Dataloader）"
      ],
      "metadata": {
        "id": "lvgR0VQpw_SV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Dataloader](https://img-blog.csdnimg.cn/b80cee8a1c7d49b79e7b80cc81150d66.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "DSqsAdWE9Vf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampler \n",
        "所有采样器都继承自Sampler这个类\n",
        "\n",
        "每个Sampler子类都要实现iter方法【迭代数据集example索引的方法】，以及返回迭代器长度的len方法"
      ],
      "metadata": {
        "id": "QS-HVTDV9xfn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sampler](https://img-blog.csdnimg.cn/1c40aedade9f40a493b4df97d0c1def0.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "HhylX0uH9Vb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 顺序采样\n",
        "![sequentialsampler](https://img-blog.csdnimg.cn/9e8ee018cea84729ac6b5742395d8ea2.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n",
        "\n",
        "***在初始化时拿到数据集data_source， 按顺序对元素进行采样，每次只返回一个索引值 ***"
      ],
      "metadata": {
        "id": "FXjatAc6BUGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 顺序采样举例\n",
        "# randperm 把 0-23 数据打乱 形成3维tensor\n",
        "# (2,3,4) batch_size:2 seq_len=3, embedding_dim=4，每个 batch 有2条数据，每个句子包含3个词， 每个词的维度是4\n",
        "a = torch.randperm(24).reshape((2,3,4))\n",
        "print('a:',a)\n",
        "b = torch.utils.data.SequentialSampler(a)\n",
        "print('b:',b)\n",
        "# i 是索引\n",
        "for i in b:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dZh5C6acm0S",
        "outputId": "f71f554d-81da-4637-c7bf-a23ad589f9d4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: tensor([[[ 5, 14,  9,  2],\n",
            "         [13, 12, 20,  1],\n",
            "         [16, 15,  7,  4]],\n",
            "\n",
            "        [[17,  0,  3, 19],\n",
            "         [10, 22,  6, 18],\n",
            "         [ 8, 23, 11, 21]]])\n",
            "b: <torch.utils.data.sampler.SequentialSampler object at 0x7f2967f65ed0>\n",
            "0\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 随机采样\n",
        "replacement : True 表示可以重复采样\n",
        "\n",
        "num_samples: 指定采样的数量\n",
        "\n",
        "PS:当使用replacement=False，不应制定num_samples\n",
        "![randomsampler](https://img-blog.csdnimg.cn/9d2e2afdbe4d4df4aee3102e46054650.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "7wyFCf2CEq7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 随机采样举例\n",
        "a = torch.randperm(60).reshape((5,3,4))\n",
        "print('a:',a)\n",
        "# 随机采样3条数据\n",
        "b = torch.utils.data.RandomSampler(a, replacement=True, num_samples=3)\n",
        "print('b:',b)\n",
        "for i in b:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52NgI_URFidd",
        "outputId": "03cb46a0-bda1-45ef-b2e3-4c743b56c50c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: tensor([[[47, 36, 58, 12],\n",
            "         [49,  7, 24,  9],\n",
            "         [27, 13, 45,  0]],\n",
            "\n",
            "        [[ 3, 28, 23, 39],\n",
            "         [37, 29, 10, 59],\n",
            "         [ 4, 35, 56, 53]],\n",
            "\n",
            "        [[54, 32, 18, 42],\n",
            "         [41, 46, 30, 14],\n",
            "         [38, 22, 11,  5]],\n",
            "\n",
            "        [[48, 33, 57, 26],\n",
            "         [15, 19, 55, 16],\n",
            "         [20, 40, 31,  6]],\n",
            "\n",
            "        [[51, 17,  1, 25],\n",
            "         [34,  2, 43, 21],\n",
            "         [52, 50,  8, 44]]])\n",
            "b: <torch.utils.data.sampler.RandomSampler object at 0x7f28834aa710>\n",
            "3\n",
            "3\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subset随机采样\n",
        "SubsetRandomSampler： 从给定的索引列表中随机采样元素，不放回采样 \n",
        "\n",
        "indices(sequence): 索引序列\n",
        "![sunsetRandomSampler](https://img-blog.csdnimg.cn/e80f6a1bafe042f28da652dc5a2388ab.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "5BoYgZchGmqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset采样举例\n",
        "a = torch.randperm(60).reshape((5,3,4))\n",
        "print('a:',a)\n",
        "# 从索引2以后的样本中随机采样\n",
        "b = torch.utils.data.SubsetRandomSampler(indices=a[2:])\n",
        "for i in b:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDJ0vAv4HCci",
        "outputId": "d1824efe-380d-4053-a5d5-9e399e9c8024"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: tensor([[[ 8, 18, 55, 16],\n",
            "         [49, 54, 14,  7],\n",
            "         [33, 37, 39,  2]],\n",
            "\n",
            "        [[45,  6, 24, 29],\n",
            "         [58, 57,  3, 47],\n",
            "         [46, 56, 26, 21]],\n",
            "\n",
            "        [[12, 25, 52, 40],\n",
            "         [ 9, 53, 10, 50],\n",
            "         [48, 59, 27, 22]],\n",
            "\n",
            "        [[ 0, 20, 34, 13],\n",
            "         [41, 32, 35, 51],\n",
            "         [15,  4, 36, 38]],\n",
            "\n",
            "        [[11, 19,  5, 43],\n",
            "         [23, 31, 44, 30],\n",
            "         [28,  1, 42, 17]]])\n",
            "tensor([[ 0, 20, 34, 13],\n",
            "        [41, 32, 35, 51],\n",
            "        [15,  4, 36, 38]])\n",
            "tensor([[12, 25, 52, 40],\n",
            "        [ 9, 53, 10, 50],\n",
            "        [48, 59, 27, 22]])\n",
            "tensor([[11, 19,  5, 43],\n",
            "        [23, 31, 44, 30],\n",
            "        [28,  1, 42, 17]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 分批采样\n",
        "sampler: 基采样器 \n",
        "\n",
        "batch_size: size of mini-batch\n",
        "\n",
        "drop_last=True, 如果一个batch的长度小于batch_size则丢弃\n",
        "![BatchSampler](https://img-blog.csdnimg.cn/8a1b2f5ae320453c9fae8ae8e0ef2080.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n",
        "\n"
      ],
      "metadata": {
        "id": "SF2c2rgKoquU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 分批采样举例\n",
        "a = torch.randperm(60).reshape((5,3,4))\n",
        "print('a:',a)\n",
        "# 要传一个基采样器torch.utils.data.RandomSampler(a)\n",
        "b = torch.utils.data.BatchSampler(torch.utils.data.RandomSampler(a), 2, drop_last=True)\n",
        "# 上面的i都是一个数；现在是batch_size的列表\n",
        "for i in b:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNi3EU11oqEc",
        "outputId": "6b3bdb21-11b5-4ad1-cc1b-fbf7acf9e2be"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: tensor([[[34, 50, 28, 24],\n",
            "         [46,  0, 35, 21],\n",
            "         [51, 52, 33, 59]],\n",
            "\n",
            "        [[31,  5, 26, 42],\n",
            "         [11, 49,  8, 29],\n",
            "         [ 9, 17, 53, 36]],\n",
            "\n",
            "        [[ 1, 37, 22, 40],\n",
            "         [18, 20, 45,  7],\n",
            "         [10, 47, 19, 32]],\n",
            "\n",
            "        [[38, 14, 58,  3],\n",
            "         [13, 25, 27, 48],\n",
            "         [ 6, 44, 55, 30]],\n",
            "\n",
            "        [[56,  2, 57, 12],\n",
            "         [ 4, 23, 16, 15],\n",
            "         [43, 54, 41, 39]]])\n",
            "[3, 4]\n",
            "[1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 桶采样\n",
        "sort_key: 按XXX排序\n",
        "\n",
        "bucket_sampler: batch_size * bucket_size_multiplier 相当于 n * batch_size\n",
        "；len(sampler)最大为数据集的长度\n",
        "![BucketSampler](https://img-blog.csdnimg.cn/6413cea5dfbf4494a6b2b64504f74a97.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "66V_qSLzuZpZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![SortedSampler](https://img-blog.csdnimg.cn/64f60217df474cf1b0d7aa1c3558cc1f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "V-VMY39qxSKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![BucketSampler](https://img-blog.csdnimg.cn/d7e03938f2824f9cb8a6c3a895f5a78a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "_WX-4OucxiqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 桶采样举例\n",
        "# Dataset -> 得到‘大桶'的排序索引\n",
        "\n",
        "# 真实train中数据，前6条\n",
        "mini_dataset = {k: v[:6] for k, v in dt['train'].items()}\n",
        "mini_data = AFQMCDataset(mini_dataset)\n",
        "print(mini_data)\n",
        "# mini_data 的前6条数据的长度\n",
        "for i, d in enumerate(mini_data):\n",
        "    print(d[0]) # input_ids\n",
        "    print(len(d[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epOJ-plhx-XG",
        "outputId": "953e4127-543c-4f6c-bd09-131bb1ab897c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.AFQMCDataset object at 0x7f287fa234d0>\n",
            "[101, 6010, 6009, 955, 1446, 5023, 7583, 6820, 3621, 1377, 809, 2940, 2768, 1044, 2622, 1400, 3315, 1408, 102, 955, 1446, 3300, 1044, 2622, 1168, 3309, 6820, 3315, 1408, 102]\n",
            "30\n",
            "[101, 6010, 6009, 5709, 1446, 6432, 2769, 6824, 5276, 671, 3613, 102, 6010, 6009, 5709, 1446, 6824, 5276, 6121, 711, 3221, 784, 720, 102]\n",
            "24\n",
            "[101, 2376, 2769, 4692, 671, 678, 3315, 3299, 5709, 1446, 6572, 1296, 3300, 3766, 3300, 5310, 3926, 102, 678, 3299, 5709, 1446, 6572, 1296, 102]\n",
            "25\n",
            "[101, 6010, 6009, 955, 1446, 1914, 7270, 3198, 7313, 5341, 1394, 6397, 844, 671, 3613, 102, 955, 1446, 2533, 6397, 844, 1914, 719, 102]\n",
            "24\n",
            "[101, 2769, 4638, 5709, 1446, 6572, 1296, 3221, 115, 115, 115, 8024, 6820, 3621, 2582, 720, 3221, 115, 115, 115, 102, 2769, 4638, 5709, 1446, 8024, 3299, 5310, 1139, 3341, 6432, 6375, 2769, 6820, 115, 115, 115, 1039, 8024, 2769, 5632, 2346, 5050, 749, 671, 678, 6422, 5301, 1399, 1296, 2769, 2418, 6421, 6820, 115, 115, 115, 1039, 102]\n",
            "59\n",
            "[101, 6010, 6009, 955, 1446, 4638, 7583, 2428, 1377, 809, 794, 4509, 6435, 679, 102, 6010, 6009, 955, 1446, 5688, 969, 3189, 1377, 809, 955, 3621, 1408, 102]\n",
            "28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bucket_sampler import SortedSampler\n",
        "random_sampler = torch.utils.data.RandomSampler(mini_data, replacement=False)\n",
        "# print(list(random_sampler))\n",
        "# 关于dataset的随机索引 [3, 5, 4, 1, 0, 2]\n",
        "\n",
        "batch_sampler = torch.utils.data.BatchSampler(random_sampler, 4, drop_last=True)\n",
        "# [0, 5, 2, 4] 【还有[1, 3] 但是丢弃了】\n",
        "\n",
        "for samp in batch_sampler:\n",
        "    print('samp:',samp)\n",
        "    sorted_sampler = SortedSampler(samp, sort_key=lambda x:len(mini_data[x][0]))\n",
        "    print('list_sorted_sampler:',list(sorted_sampler))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Yyjconvz6TO",
        "outputId": "b9fc99ff-2e7b-440c-f666-c5255ce75d13"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "samp: [0, 3, 1, 4]\n",
            "list_sorted_sampler: [1, 2, 0, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "[0, 5, 2, 4]分别对应mini_data中的长度[30, 28, 25, 59]\n",
        "\n",
        "[2, 1, 0, 3] \n",
        "\n",
        "2（位置2的数据len最小） -> 2 -> 25 \n",
        "\n",
        "1 -> 5 -> 28 \n",
        "\n",
        "0 -> 0 -> 30 \n",
        "\n",
        "3（位置3的数据len最大） -> 4 -> 59\n",
        "```"
      ],
      "metadata": {
        "id": "-A6oFU9B1RXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 得到‘大桶'的排序索引 -> 返回‘小桶'在‘大桶'中的位置\n",
        "c = list(torch.utils.data.BatchSampler(sorted_sampler, 2, drop_last=True))\n",
        "print(c)\n",
        "# c 把大桶 分成 batch_size大小的小桶"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az7SLVSs2idz",
        "outputId": "4bc2a4ed-e6ed-40de-bf03-14e6bab953d3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2], [0, 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "[[2, 1], [0, 3]]\n",
        "```"
      ],
      "metadata": {
        "id": "ABvwvlmZ5_r5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in torch.utils.data.SubsetRandomSampler(c):\n",
        "    print('从给定的索引列表中随机采样元素')\n",
        "    print(batch)\n",
        "    print('所对应的原序列是什么：')\n",
        "    print([samp[i] for i in batch])\n",
        "    # 参考上面 from bucket_sampler import SortedSampler 单元格对应法则"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGcdBAPo3Za7",
        "outputId": "ae0a023d-144e-4632-c492-74ec2640890c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "从给定的索引列表中随机采样元素\n",
            "[1, 2]\n",
            "所对应的原序列是什么：\n",
            "[3, 1]\n",
            "从给定的索引列表中随机采样元素\n",
            "[0, 3]\n",
            "所对应的原序列是什么：\n",
            "[0, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "从给定的索引列表中随机采样元素\n",
        "[2, 1]\n",
        "所对应的原序列是什么：\n",
        "[2, 5]\n",
        "从给定的索引列表中随机采样元素\n",
        "[0, 3]\n",
        "所对应的原序列是什么：\n",
        "[0, 4]\n",
        "```"
      ],
      "metadata": {
        "id": "l_W55Rvx5WxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 采样在dataloader中使用\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import RandomSampler\n",
        "from bucket_sampler import BucketBatchSampler\n",
        "\n",
        "def build_dataloader(config, data, collate_fn):\n",
        "  train_dataset = AFQMCDataset(data['train'])\n",
        "  dev_dataset = AFQMCDataset(data['dev'])\n",
        "  test_dataset = AFQMCDataset(data['test'])\n",
        "\n",
        "  if config['use_bucket']:\n",
        "    # 先放一个基采样器\n",
        "    train_sampler = RandomSampler(train_dataset)\n",
        "    # sort_key 以input_ids 的len排序\n",
        "    bucket_sampler = BucketBatchSampler(train_sampler, \n",
        "                       batch_size = config['batch_size'],\n",
        "                       drop_last = False,\n",
        "                       sort_key = lambda x:len(train_dataset[x][0]),\n",
        "                       bucket_size_multiplier = config['bucket_multiplier'])\n",
        "    train_dataloader = DataLoader(dataset = train_dataset, batch_sampler = bucket_sampler,\n",
        "                    num_workers = 4, collate_fn = collate_fn)\n",
        "    \n",
        "  else:\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size = config['batch_size'],\n",
        "                    shuffle = True, num_workers = 4, collate_fn = collate_fn)\n",
        "  dev_dataloader = DataLoader(dev_dataset, batch_size = config['batch_size'],\n",
        "                  shuffle = False, num_workers = 4, collate_fn = collate_fn)\n",
        "  test_dataloader = DataLoader(test_dataset, batch_size = config['batch_size'],\n",
        "                  shuffle = False, num_workers = 4, collate_fn = collate_fn)\n",
        "  return train_dataloader, dev_dataloader, test_dataloader  \n"
      ],
      "metadata": {
        "id": "UwqaHWKQ_qJV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, dev_dataloader, test_dataloader = build_dataloader(config, dt, collate_fn)"
      ],
      "metadata": {
        "id": "ck6rtFpEAQ70"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in train_dataloader:\n",
        "    print('train_dataloader一个batch:',i)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5epRv3qR2mC",
        "outputId": "867256cc-ba5c-4352-aa39-c80bfe96c9bf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataloader一个batch: {'input_ids': tensor([[ 101, 2769,  671,  ...,  955, 1446,  102],\n",
            "        [ 101,  671, 2476,  ..., 1126,  702,  102],\n",
            "        [ 101, 2769, 4500,  ..., 1168, 6572,  102],\n",
            "        ...,\n",
            "        [ 101, 2769, 4638,  ..., 1921, 6820,  102],\n",
            "        [ 101, 2769, 4638,  ..., 5709, 1446,  102],\n",
            "        [ 101, 2769,  955,  ...,  955, 1446,  102]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
            "        1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 自动混合精度（混合精度训练）\n",
        "\n",
        "![amp](https://img-blog.csdnimg.cn/e4226734b82f462e983aa905de50891a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n"
      ],
      "metadata": {
        "id": "fDXEWnmmAQlk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 混合精度训练\n",
        "作用：训练时，尽量不降低性能，并提升速度 \n",
        "\n",
        "Float16优点:\n",
        "\n",
        "* 减少内存的使用\n",
        "* 加快训练和推断的计算，能带来多一倍速的体验\n",
        "\n",
        "Float16缺点:\n",
        "* 溢出错误\n",
        "* 舍入误差"
      ],
      "metadata": {
        "id": "bIV8wdDKpjpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.FloatTensor 32位\n",
        "a = torch.zeros(2,3)\n",
        "print(a.type())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrzjvFGxDNqo",
        "outputId": "976b93f7-2fa2-46e2-9283-00cde9247cb4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.FloatTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "混合精度将 ***autocast*** 和 ***GradScaler*** 一起使用"
      ],
      "metadata": {
        "id": "u0K13AmcEtwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***当进入autocast()时， 系统自动切换为float16, autocast上下文只包含前向传播，建议不用反向传播***"
      ],
      "metadata": {
        "id": "61kZsJEeEB0A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![amp2](https://img-blog.csdnimg.cn/72b642b508024cc2a6207c308347c7e7.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "WJZyS-0hwR9t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gradient Scaling\n",
        "* scaler.scale(loss) 将给定的损失乘以缩放器的当前比例因子，进行反向传播\n",
        "* scaler.step(optimizer) 取消缩放梯度并调用optimizer.step()\n",
        "* scaler.update() 更新缩放器的比例因子"
      ],
      "metadata": {
        "id": "sn1VIDX5ETYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![scaling](https://img-blog.csdnimg.cn/bbae5cdd360748ecb59cee8dc6f728f2.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "J8rDZvQnwXVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![GradScaler](https://img-blog.csdnimg.cn/2c0fdf08602748ea8a7655f2d5bb1829.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "lrT4nqUiway0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![example](https://img-blog.csdnimg.cn/dfeebde4d34b496096062bb7dbbee7b6.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "eSAb4I01wdOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(config, model, val_dataloader):\n",
        "  model.eval()\n",
        "  preds = []\n",
        "  labels = []\n",
        "  val_loss = 0.\n",
        "  val_iterator = tqdm(val_dataloader, desc = 'Evaluation', total = len(val_dataloader))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in val_iterator:\n",
        "      labels.append(batch['labels'])\n",
        "      batch_cuda = {item: value.to(config['device']) for item, value in list(batch.items())}\n",
        "      loss, logits = model(**batch_cuda)[:2]\n",
        "\n",
        "      if config['n_gpus'] > 1:\n",
        "        loss = loss.mean()\n",
        "\n",
        "      val_loss += loss.item()\n",
        "      preds.append(logits.argmax(dim = -1).detach().cpu())\n",
        "\n",
        "  avg_val_loss = val_loss / len(val_dataloader)\n",
        "  labels = torch.cat(labels, dim = 0).numpy()\n",
        "  preds = torch.cat(preds, dim = 0).numpy()\n",
        "  f1 = metrics.f1_score(labels, preds)\n",
        "  acc = mrtrics.accuracy_score(labels, preds)\n",
        "  return avg_val_loss, f1, acc"
      ],
      "metadata": {
        "id": "gG3kyfNQ7Xcu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EMA:\n",
        "  def __init__(self, model, decay):\n",
        "    self.model = model\n",
        "    self.decay = decay\n",
        "    self.shadow = {}\n",
        "    self.backup = {}\n",
        "    self.register = {}\n",
        "\n",
        "  def register(self):\n",
        "    for name, param in self.model.named_parameters():\n",
        "      if param.requires_grad:\n",
        "        self.shadow[name] = param.data.clone()\n",
        "\n",
        "  def update(self):\n",
        "    for name, param in self.model.named_parameters():\n",
        "      if param.requires_grad:\n",
        "        # 如果 name in self.shadow 则运行下面两行代码， 否则报错\n",
        "        assert name in self.shadow\n",
        "        new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]\n",
        "        self.shadow[name] = new_average.clone()\n",
        "\n",
        "  def apply_shadow(self):\n",
        "    for name, param in self.model.named_parameters():\n",
        "      if param.requires_grad:\n",
        "        assert name in self.shadow\n",
        "        self.backup[name] = param.data\n",
        "        param.data = self.shadow[name]\n",
        "\n",
        "  def restore(self):\n",
        "    for name, param in self.model.named_parameters():\n",
        "      if param.requires_grad:\n",
        "        assert name in self.backup\n",
        "        param.data = self.backup[name]\n",
        "    self.backup = {}\n",
        "  "
      ],
      "metadata": {
        "id": "j2yDMxscHcem"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "from torch.cuda import amp\n",
        "from transformers import AdamW\n",
        "from extra_pgd import *\n",
        "from extra_loss import *\n",
        "from extra_fgm import *\n",
        "from extra_optim import *\n",
        "from tqdm import trange\n",
        "def train(config, train_dataloader, dev_dataloader):\n",
        "  # 封装好 BertForSequenceClassification\n",
        "  model = BertForSequenceClassification.from_pretrained(config['model_path'])\n",
        "\n",
        "  # param_optimizer = model.named_parameters()\n",
        "  param_optimizer = list(model.named_parameters())\n",
        "\n",
        "  # 实例化scaler对象 enabled=True 可以使用梯度缩放\n",
        "  scaler = amp.GradScaler(enabled = config['use_amp'])\n",
        "\n",
        "  # 权重缩减\n",
        "  no_decay = ['bias', 'LayerNorm.weight']\n",
        "\n",
        "  # 名称包含 ['bias', 'LayerNorm.weight']的权重， 其权重衰减因子为0\n",
        "  # 名称不包含 ['bias', 'LayerNorm.weight']的权重， 其权重衰减因子为 0.01\n",
        "  # any() 理解成any True的意思，是否存在True，只要有一个是True，结果就是True\n",
        "  optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay': config['weight_decay']},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay': 0.0}\n",
        "  ]\n",
        "\n",
        "  optimizer = AdamW(optimizer_grouped_parameters, lr = config['learning_rate'],\n",
        "            eps = 1e-8)\n",
        "  \n",
        "  # lookahead 预先查看由 AdamW 生成的快速权重 来选择搜索方向\n",
        "  optimizer = Lookahead(optimizer, 5, 1)\n",
        "  total_steps = config['num_epochs'] * len(train_dataloader)\n",
        "\n",
        "  # 使用Warmup来调整学习率，每调用warmup_steps次，对应的学习率就会调整一次。\n",
        "  lr_scheduler = WarmupLinearSchedule(optimizer, warmup_steps = int(config['warmup_ratio'] * total_steps),\n",
        "                     t_total = total_steps)\n",
        "  \n",
        "\n",
        "                                  \n",
        "  model.to(config['device'])\n",
        "\n",
        "  if config['adv'] == 'fgm':\n",
        "    fgm = FGM(model)\n",
        "  else:\n",
        "    pgd = PGD(model)\n",
        "    K = 3\n",
        "\n",
        "  epoch_iterator = trange(config['num_epochs'])\n",
        "  global_steps = 0\n",
        "  train_loss = 0.\n",
        "  logging_loss = 0.\n",
        "  best_acc = 0.\n",
        "  best_model_path = ''\n",
        "\n",
        "  # 多卡情况\n",
        "  if config['n_gpus'] > 1:\n",
        "    model = nn.DataParallel(model)\n",
        "  for _ in epoch_iterator:\n",
        "    train_iterator = tqdm(train_dataloader, desc = 'Trainging', total = len(train_dataloader))\n",
        "    model.train()\n",
        "    for batch in train_iterator:\n",
        "      batch_cuda = {item: value.to(config['device']) for item, value in list(batch.items())}\n",
        "\n",
        "      # 前向过程（前向传播 + loss）\n",
        "      with amp.autocast(enabled = config['use_amp']):\n",
        "        loss = model(**batch_cuda)[0]\n",
        "        # 多卡 取平均\n",
        "        if config['n_gpus'] > 1:\n",
        "          loss = loss.mean()\n",
        "        \n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "      if config['adv'] == 'fgm':\n",
        "          # 在embedding上加扰动\n",
        "        fgm.attack(epsilon = config['eps'])\n",
        "\n",
        "          # autocast\n",
        "        with amp.autocast(enabled = config['use_amp']):\n",
        "          loss_adv = model(**batch_cuda)[0]\n",
        "\n",
        "          if config['n_gpus'] > 1:\n",
        "            loss_adv =loss_adv.mean()\n",
        "\n",
        "        scaler.scale(loss_adv).backward()\n",
        "        # 恢复embedding参数\n",
        "        fgm.restore()\n",
        "      else:\n",
        "        pgd.backup_grad()\n",
        "        for t in range(K):\n",
        "          pgd.attack(epsilon = config['eps'], alpha = config['alpha'], is_first_attack= ( t == 0))\n",
        "          if t != K - 1:\n",
        "            model.zero_grad()\n",
        "          else:\n",
        "            pgd.restore_grad()\n",
        "          with amp.autocast(enabled = config['use_amp']):\n",
        "            loss_adv = model(**batch_cuda)[0]\n",
        "            if config['n_gpus'] > 1:\n",
        "              loss_adv = loss_adv.mean()\n",
        "\n",
        "          scaler.scale(loss_adv).backward()\n",
        "        pgd.restore()\n",
        "        \n",
        "      scaler.step(optimizer)\n",
        "      scaler.update()\n",
        "\n",
        "      lr_scheduler.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      if config['ema_start']:\n",
        "        ema.update()\n",
        "        \n",
        "      train_loss += loss.item()\n",
        "      global_steps += 1\n",
        "\n",
        "      train_iterator.set_postfix_str(f'running train loss: {loss.item():.5f}')\n",
        "\n",
        "      if global_steps % config['logging_step'] == 0:\n",
        "        if global_steps >= config['ema_start_step'] and not config['ema_start']:\n",
        "          print('\\n>>> EMA starting .....')\n",
        "          config['ema_start'] = True\n",
        "\n",
        "          ema = EMA(model.module if hasattr(model, 'module') else model, decay = 0.99)\n",
        "\n",
        "        print_train_loss = (train_loss - logging_loss) / config['logging_step']\n",
        "        logging_loss = train_loss\n",
        "\n",
        "        if config['ema_start']:\n",
        "          ema.apply_shadow()\n",
        "        val_loss, f1, acc = evaluation(config, model, dev_dataloader)\n",
        "\n",
        "        print_log = f'\\n>>> training loss: {print_train_loss:.6f}, valid loss: {val_loss:.6f},' \n",
        "\n",
        "        if acc > best_acc:\n",
        "          model_save_path = os.path.join(config['output_path'],\n",
        "                          f'checkpoint- {global_steps} - {acc:.6f}')\n",
        "          model_to_save = model.module if hasattr(model, 'module') else model\n",
        "          model_to_save.save_pretrained(model_save_path)\n",
        "          best_acc = acc\n",
        "          best_model_path = model_save_path\n",
        "        print_log += f'valid f1: {f1:.6f}, valid acc:{acc:.6f}'\n",
        "\n",
        "        print(print_log)\n",
        "        model.train()\n",
        "\n",
        "        if config['ema_start']:\n",
        "          ema.restore()\n",
        "\n",
        "\n",
        "  return model, best_model_path        \n",
        "\n",
        "      "
      ],
      "metadata": {
        "id": "91xvXsDETp7m"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(config, train_dataloader, dev_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "mpCUDSWDk2hk",
        "outputId": "ddf54d61-c146-4e43-ec5a-b9f709522079"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/Colab Notebooks/dataset/BERT_model were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/dataset/BERT_model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Trainging:   0%|          | 0/537 [00:00<?, ?it/s]\u001b[A\n",
            "Trainging:   0%|          | 0/537 [00:05<?, ?it/s, running train loss: 0.62231]\u001b[A\n",
            "Trainging:   0%|          | 1/537 [00:05<47:28,  5.32s/it, running train loss: 0.62231]\u001b[A\n",
            "Trainging:   0%|          | 1/537 [00:09<47:28,  5.32s/it, running train loss: 0.61432]\u001b[A\n",
            "Trainging:   0%|          | 2/537 [00:09<43:57,  4.93s/it, running train loss: 0.61432]\u001b[A\n",
            "Trainging:   0%|          | 2/537 [00:13<43:57,  4.93s/it, running train loss: 0.61790]\u001b[A\n",
            "Trainging:   1%|          | 3/537 [00:13<39:43,  4.46s/it, running train loss: 0.61790]\u001b[A\n",
            "Trainging:   1%|          | 3/537 [00:17<39:43,  4.46s/it, running train loss: 0.54319]\u001b[A\n",
            "Trainging:   1%|          | 4/537 [00:17<35:43,  4.02s/it, running train loss: 0.54319]\u001b[A\n",
            "Trainging:   1%|          | 4/537 [00:20<35:43,  4.02s/it, running train loss: 0.59943]\u001b[A\n",
            "Trainging:   1%|          | 5/537 [00:23<42:04,  4.74s/it, running train loss: 0.59943]\n",
            "  0%|          | 0/1 [00:23<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-8292e8ae5741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-2e7a277e6c3e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config, train_dataloader, dev_dataloader)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mloss_adv\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mloss_adv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_adv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;31m# 恢复embedding参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mfgm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}