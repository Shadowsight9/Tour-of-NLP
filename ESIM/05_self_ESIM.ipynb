{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_self_ESIM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faxwvxbp34mR",
        "outputId": "2a340914-325d-4c84-c996-e18bf9f65955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 19 08:47:13 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P8    35W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "#设置路径\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd2KAF6r4j-J",
        "outputId": "776ba47b-b437-4fa4-c30d-f9389a892368"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers==4.0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwtR4C9e5Vca",
        "outputId": "d593cb4b-17c1-4d3f-c8b2-d91cba936cb5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.0.1 in /usr/local/lib/python3.7/dist-packages (4.0.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (0.0.49)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (0.9.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (4.64.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (1.21.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.0.1) (3.0.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "config = {\n",
        "    'train_file_path':'/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/train.json',\n",
        "    'dev_file_path':'/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/dev.json',\n",
        "    'test_file_path':'/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/test.json',\n",
        "    'embedding_file_path':'/content/drive/MyDrive/Colab Notebooks/dataset/sgns.weibo.word.bz2',\n",
        "    'train_val_ratio':0.1,\n",
        "    'vocab_size':30000,\n",
        "    'batch_size':64,\n",
        "    # 从后面可以看出 64能容纳99%的句子长度\n",
        "    'max_seq_len':64,\n",
        "    'num_epochs':1,\n",
        "    'learning_rate':2e-5,\n",
        "    'logging_step':500,\n",
        "    'seed':2022\n",
        "}\n",
        "\n",
        "config['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def seed_everything(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  return seed\n",
        "\n",
        "seed_everything(config['seed'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mdTOeMT6U1w",
        "outputId": "dbc3c5d4-1745-4b9c-c043-38fec352a8cb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2022"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "def read_data(path):\n",
        "  sentence_a = []\n",
        "  sentence_b = []\n",
        "  labels = []\n",
        "  with open(path, 'r', encoding='utf8') as f:\n",
        "    for line in tqdm(f.readlines(), desc='Reading data'):\n",
        "      line = json.loads(line)\n",
        "      sentence_a.append(line['sentence1'])\n",
        "      sentence_b.append(line['sentence2'])\n",
        "      labels.append(int(line['label']))\n",
        "  \n",
        "  df = pd.DataFrame(zip(sentence_a, sentence_b, labels), columns=['text_a','text_b','labels'])\n",
        "  return df"
      ],
      "metadata": {
        "id": "v9eF7CtP5ado"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 复习一下zip函数:\n",
        "# 这里有两个元组()，每个元组有两个句子，一个label\n",
        "datas = [([1,2,3],[4,5,6],1),([777,888,999],[321,543,654],0)]\n",
        "# 取出列表中每个元素（元组）\n",
        "print(*datas)\n",
        "print(zip(*datas))\n",
        "# 把 datas 中的同一类别的放在一起\n",
        "print(list(zip(*datas)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkIjefdbLZnZ",
        "outputId": "092b3335-afd6-416a-f31c-2508a825e24b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([1, 2, 3], [4, 5, 6], 1) ([777, 888, 999], [321, 543, 654], 0)\n",
            "<zip object at 0x7f061389f910>\n",
            "[([1, 2, 3], [777, 888, 999]), ([4, 5, 6], [321, 543, 654]), (1, 0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = read_data(config['train_file_path'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6SDvo_BHzxr",
        "outputId": "6d5fc162-665a-444f-a83a-aec63dffe4b4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading data: 100%|██████████| 34334/34334 [00:00<00:00, 78693.38it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "u7g5tNarIggE",
        "outputId": "2bac7454-d169-41e4-fe1e-d9c2717bc705"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                text_a                                 text_b  labels\n",
              "0    蚂蚁借呗等额还款可以换成先息后本吗                             借呗有先息到期还本吗       0\n",
              "1           蚂蚁花呗说我违约一次                            蚂蚁花呗违约行为是什么       0\n",
              "2     帮我看一下本月花呗账单有没有结清                                 下月花呗账单       0\n",
              "3       蚂蚁借呗多长时间综合评估一次                                借呗得评估多久       0\n",
              "4  我的花呗账单是***，还款怎么是***  我的花呗，月结出来说让我还***元，我自己算了一下详细名单我应该还***元       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25fc3181-3636-4370-9bd6-9a81e38a58fb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_a</th>\n",
              "      <th>text_b</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>蚂蚁借呗等额还款可以换成先息后本吗</td>\n",
              "      <td>借呗有先息到期还本吗</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>蚂蚁花呗说我违约一次</td>\n",
              "      <td>蚂蚁花呗违约行为是什么</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>帮我看一下本月花呗账单有没有结清</td>\n",
              "      <td>下月花呗账单</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>蚂蚁借呗多长时间综合评估一次</td>\n",
              "      <td>借呗得评估多久</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>我的花呗账单是***，还款怎么是***</td>\n",
              "      <td>我的花呗，月结出来说让我还***元，我自己算了一下详细名单我应该还***元</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25fc3181-3636-4370-9bd6-9a81e38a58fb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-25fc3181-3636-4370-9bd6-9a81e38a58fb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-25fc3181-3636-4370-9bd6-9a81e38a58fb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_df = read_data(config['dev_file_path'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEQpzZ1qI7FB",
        "outputId": "7f5d864b-1eb7-4147-8ee0-bbd15ed13e8a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading data: 100%|██████████| 4316/4316 [00:00<00:00, 63881.74it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "xYHahZ0BJBLJ",
        "outputId": "c2b76f3c-925c-4125-f414-b00690b9124d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             text_a                text_b  labels\n",
              "0         双十一花呗提额在哪              里可以提花呗额度       0\n",
              "1        花呗支持高铁票支付吗         为什么友付宝不支持花呗付款       0\n",
              "2  我的蚂蚁花呗支付金额怎么会有限制  我到支付宝实体店消费用花呗支付受金额限制       1\n",
              "3    为什么有花呗额度不能分期付款              花呗分期额度不足       0\n",
              "4       赠品不能设置用花呗付款            怎么不能花呗分期付款       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-caad49ac-6e31-4d6f-acea-e4732508ac7f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_a</th>\n",
              "      <th>text_b</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>双十一花呗提额在哪</td>\n",
              "      <td>里可以提花呗额度</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>花呗支持高铁票支付吗</td>\n",
              "      <td>为什么友付宝不支持花呗付款</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>我的蚂蚁花呗支付金额怎么会有限制</td>\n",
              "      <td>我到支付宝实体店消费用花呗支付受金额限制</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>为什么有花呗额度不能分期付款</td>\n",
              "      <td>花呗分期额度不足</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>赠品不能设置用花呗付款</td>\n",
              "      <td>怎么不能花呗分期付款</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-caad49ac-6e31-4d6f-acea-e4732508ac7f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-caad49ac-6e31-4d6f-acea-e4732508ac7f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-caad49ac-6e31-4d6f-acea-e4732508ac7f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_df.text_a.str.len() + train_df.text_b.str.len()).hist(bins = 20);\n",
        "(dev_df.text_a.str.len() + dev_df.text_b.str.len()).hist(bins = 20);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "8wo2ged9JNGI",
        "outputId": "474758bd-3a4a-4ac0-e41b-5a0dcba1fe39"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 64能容纳99%的句子长度\n",
        "(train_df.text_a.str.len() + train_df.text_b.str.len()).quantile(0.99)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpJl4UuwJmAC",
        "outputId": "1c9826bc-2448-4423-c161-2b3e5391c5e3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64.0"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 处理文件，生层词表放回关于train_df[train.json + dev.json],test_df\n",
        "from collections import Counter\n",
        "import jieba\n",
        "import bz2\n",
        "def preprocess(config):\n",
        "  def convert2df(file_path, dataset='train'):\n",
        "    sentence_a = []\n",
        "    sentence_b = []\n",
        "    labels = []\n",
        "    with open(file_path, 'r', encoding='utf8') as f:\n",
        "      for line in tqdm(f.readlines(), desc=f'Reading {dataset} data'):\n",
        "        line = json.loads(line)\n",
        "        sentence_a.append(line['sentence1'])\n",
        "        sentence_b.append(line['sentence2'])\n",
        "        if dataset != 'test':\n",
        "          labels.append(int(line['label']))\n",
        "        else:\n",
        "          labels.append(0)\n",
        "        # tokens为每次新加入的句子\n",
        "        tokens = list(jieba.cut(sentence_a[-1])) + list(jieba.cut(sentence_b[-1])) \n",
        "        # print('tokens:',tokens)\n",
        "        # tokens: ['蚂蚁', '花', '呗', '说', '我', '违约', '一次', '蚂蚁', '花', '呗', '违约', '行为', '是', '什么']\n",
        "        token_counter.update(tokens)\n",
        "    df = pd.DataFrame(zip(sentence_a,sentence_b,labels),columns=['text_a','text_b','labels'])\n",
        "    return df\n",
        "  \n",
        "  token_counter = Counter()\n",
        "\n",
        "  train_df = convert2df(config['train_file_path'],'train')\n",
        "  dev_df = convert2df(config['dev_file_path'],'dev')\n",
        "  test_df = convert2df(config['test_file_path'],'test')\n",
        "\n",
        "  train_df = train_df.append(dev_df)\n",
        "  vocab = set(token for token, _ in token_counter.most_common(config['vocab_size']))\n",
        "  # print('vocab:',vocab)\n",
        "  # vocab: {'城', '帮不上', '百度', '钱分', '会加分', '我晚', '手机短信'.......}\n",
        "  return train_df, test_df, vocab\n",
        "\n"
      ],
      "metadata": {
        "id": "64kVEP5GBNg6"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df, vocab = preprocess(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmSHkwAyEwmI",
        "outputId": "90a1c998-77f0-49e2-b7e5-3772fad13d6d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading train data: 100%|██████████| 34334/34334 [00:08<00:00, 4248.86it/s]\n",
            "Reading dev data: 100%|██████████| 4316/4316 [00:01<00:00, 3797.17it/s]\n",
            "Reading test data: 100%|██████████| 3861/3861 [00:00<00:00, 4353.15it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TextCNN 词表对应成向量\n",
        "def get_embedding(vocab, embedding_file_path):\n",
        "  print('processing embedding file, please wait...')\n",
        "\n",
        "  token2embedding = {}\n",
        "\n",
        "  with bz2.open(embedding_file_path) as f:\n",
        "    token_vectors = f.readlines()\n",
        "    # print('token_vectors:',list(token_vectors[0:10]))\n",
        "    # token_vectors: [b'195202 300\\n', b'\\xef\\xbc\\x8c 0.094386 -0.200944 -0.030828 0.277130 ... 0.126182 -0.554329 -0.328050 \\n', b'......\\n'...]\n",
        "    meta_info = token_vectors[0].split()\n",
        "    # print('meta_info:',meta_info)\n",
        "    # meta_info: [b'195202', b'300']\n",
        "    print(f'{meta_info[0]} tokens in embedding file in total, vector size is {meta_info[-1]}')\n",
        "\n",
        "    for line in tqdm(token_vectors[1:]):\n",
        "      line = line.split()\n",
        "      token = line[0].decode('utf8')\n",
        "      # print('token:',token)\n",
        "      # token: ！\n",
        "      # token: 可以\n",
        "      # token: 等\n",
        "      # ...\n",
        "      vector = line[1:]\n",
        "      if token in vocab:\n",
        "        token2embedding[token] = [float(num) for num in vector]\n",
        "        # print('token2embedding[token]:',token2embedding[token])\n",
        "        # token2embedding[token]: [-0.124044, -0.053688, 0.157958, ... -0.127075, -0.020528, 0.032646]\n",
        "  #从4开始\n",
        "  token2idx = {token: idx for idx, token in enumerate(token2embedding.keys(),4)}\n",
        "  UNK, PAD, BOS, EOS = '<unk>', '<pad>', '<bos>', '<eos>'\n",
        "  token2idx[PAD] = 0 \n",
        "  token2idx[UNK] = 1\n",
        "  token2idx[BOS] = 2\n",
        "  token2idx[EOS] = 3\n",
        "  idx2token = {idx: token for token, idx in token2idx.items()}\n",
        "  idx2embedding = {token2idx[token]: embedding for token, embedding in token2embedding.items()}\n",
        "\n",
        "  idx2embedding[0] = [.0] * int(meta_info[-1])\n",
        "  idx2embedding[1] = [.0] * int(meta_info[-1])\n",
        "  idx2embedding[2] = np.random.random(int(meta_info[-1])).tolist()\n",
        "  idx2embedding[3] = np.random.random(int(meta_info[-1])).tolist()\n",
        "  emb_mat = [idx2embedding[idx] for idx in range(len(idx2embedding))]\n",
        "\n",
        "  return torch.tensor(emb_mat, dtype=torch.float), token2idx, len(vocab) + 4"
      ],
      "metadata": {
        "id": "U0PRXceWF3Fv"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix, token2idx, config['vocab_size'] = get_embedding(vocab, config['embedding_file_path'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD-tn73jSuBi",
        "outputId": "99c09a71-22e7-482b-d05e-982ebb922deb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing embedding file, please wait...\n",
            "b'195202' tokens in embedding file in total, vector size is b'300'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 195202/195202 [00:03<00:00, 56866.28it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "def tokenizer(sent, token2id):\n",
        "  # .get() 找到返回 token的id, 没找到就返回 1 1->UNK\n",
        "  ids = [token2id.get(token, 1) for token in jieba.cut(sent)]\n",
        "  return ids"
      ],
      "metadata": {
        "id": "qgfv519gw_JU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "df = pd.DataFrame(np.random.randn(4, 3), columns = ['col1', 'col2', 'col3'])\n",
        "df\n",
        "\n",
        "\tcol1\t  col2\t   col3\n",
        "0\t0.956880\t0.787811\t0.099237\n",
        "1\t0.413166\t-0.541869\t0.548336\n",
        "2\t0.951179\t0.113981\t1.130187\n",
        "3\t0.802346\t1.953860\t-2.062042\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "  print('i:',i,'row:',row)\n",
        "\n",
        "i: 0 row: col1    0.956880\n",
        "col2    0.787811\n",
        "col3    0.099237\n",
        "Name: 0, dtype: float64\n",
        "i: 1 row: col1    0.413166\n",
        "col2   -0.541869\n",
        "col3    0.548336\n",
        "Name: 1, dtype: float64\n",
        "i: 2 row: col1    0.951179\n",
        "col2    0.113981\n",
        "col3    1.130187\n",
        "Name: 2, dtype: float64\n",
        "i: 3 row: col1    0.802346\n",
        "col2    1.953860\n",
        "col3   -2.062042\n",
        "Name: 3, dtype: float64\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "  print('row[0]:',row[0])\n",
        "\n",
        "row[0]: 0.9568798249976214\n",
        "row[0]: 0.41316597459220283\n",
        "row[0]: 0.9511794577235149\n",
        "row[0]: 0.8023455023210482\n",
        "```"
      ],
      "metadata": {
        "id": "6-qPPSz-z9rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(data_df, train_val_ratio, token2id, mode = 'train'):\n",
        "  if mode == 'train':\n",
        "    X_train, y_train = defaultdict(list),[]\n",
        "    X_val, y_val = defaultdict(list),[]\n",
        "    num_val = int(len(data_df) * train_val_ratio)\n",
        "  else:\n",
        "    X_test, y_test = defaultdict(list),[]\n",
        "  \n",
        "  for i, row in tqdm(data_df.iterrows(), desc=f'Preprocessing {mode} data', total = len(data_df)):\n",
        "    text_left = row[0]\n",
        "    text_right = row[1]\n",
        "    label = row[2]\n",
        "\n",
        "    input_a = tokenizer(text_left, token2id = token2idx)\n",
        "    input_b = tokenizer(text_right, token2id = token2idx)\n",
        "    \n",
        "    if mode == 'train':\n",
        "      if i<num_val:\n",
        "        X_val['text_left'].append(input_a)\n",
        "        X_val['text_right'].append(input_b)\n",
        "        y_val.append(label)\n",
        "      else:\n",
        "        X_train['text_left'].append(input_a)\n",
        "        X_train['text_right'].append(input_b)\n",
        "        y_train.append(label)\n",
        "    else:\n",
        "      X_test['text_left'].append(input_a)\n",
        "      X_test['text_right'].append(input_b)\n",
        "      y_test.append(label)\n",
        "\n",
        "  if mode == 'train':\n",
        "    label2id = {label : i for i,label in enumerate(np.unique(y_train))}\n",
        "    id2label = {i : label for label, i in label2id.items()}\n",
        "    y_train = torch.tensor([label2id[label] for label in y_train], dtype= torch.long)\n",
        "    y_val = torch.tensor([label2id[label] for label in y_val], dtype= torch.long)\n",
        "    return X_train, y_train, X_val, y_val, label2id, id2label\n",
        "  else:\n",
        "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "    return X_test, y_test"
      ],
      "metadata": {
        "id": "l8ICD-VFxjym"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_val, y_val, label2id, id2label = read_data(train_df, config['train_val_ratio'], token2idx, mode='train')\n",
        "X_test, y_test = read_data(test_df, config['train_val_ratio'], token2idx, mode='test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJxabq4n4zYw",
        "outputId": "ef8d4976-480e-40a6-de9f-2bc628e7e70f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocessing train data: 100%|██████████| 38650/38650 [00:12<00:00, 2991.55it/s]\n",
            "Preprocessing test data: 100%|██████████| 3861/3861 [00:01<00:00, 3022.47it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class AFQMCDataset(Dataset):\n",
        "  def __init__(self, x, y):\n",
        "    super(AFQMCDataset, self).__init__()\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    data = (self.x['text_left'][idx],\n",
        "         self.x['text_right'][idx],\n",
        "         self.y[idx]   \n",
        "            )\n",
        "    return data\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.y.size(0)#行数"
      ],
      "metadata": {
        "id": "4FM96AIK-19O"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "TextCNN中collete_fn函数\n",
        "def collete_fn(examples):\n",
        "    input_ids_list = []\n",
        "    labels =[]\n",
        "    for example in examples:\n",
        "        input_ids_list.append(example['input_ids'])\n",
        "        labels.append(example['label'])\n",
        "\n",
        "    # 对齐操作 -- 找到 input_ids_list 中 最长的 句子， 执行短句子补齐\n",
        "    # 1. 找到 input_ids_list 中 最长的 句子\n",
        "    max_length = max(len(input_ids) for input_ids in input_ids_list) \n",
        "    # 2. 定义一个 input_ids_tensor, 我们要把 每个 input_ids 放入 tensor 中\n",
        "    input_ids_tensor = torch.zeros((len(labels), max_length), dtype=torch.long)\n",
        "    for i, input_ids in enumerate(input_ids_list):\n",
        "        # 得到当前句子的长度\n",
        "        seq_len = len(input_ids)\n",
        "        # 第i个句子，填充 seq_len 这么长\n",
        "        input_ids_tensor[i, :seq_len] = torch.tensor(input_ids, dtype=torch.long)\n",
        "\n",
        "    return {\n",
        "        'input_ids' : input_ids_tensor,\n",
        "        'labels' : torch.tensor(labels, dtype=torch.long)\n",
        "    }\n",
        "```"
      ],
      "metadata": {
        "id": "f42aK8fiAagL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# __call__方法的调用\n",
        "class MyClass():\n",
        "  def __call__(self):\n",
        "    print('__call__方法被调用')\n",
        "    return 'done'"
      ],
      "metadata": {
        "id": "SngM5VBdATU8"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 类实例化\n",
        "obj = MyClass()"
      ],
      "metadata": {
        "id": "mxbuYVYqBhnk"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 实例化的对象 当作函数用\n",
        "res = obj()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mru9AQZJBlEr",
        "outputId": "cb9a9af2-80de-4dc6-ca54-0458b241e641"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__call__方法被调用\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 从 AFQMCDataset 输出的 data  = (sentence1, sentence2, label])\n",
        "# 1. 将元组中属于sentence1的放在一起，属于sentence2的放在一起，属于label的放在一起\n",
        "# 2. 对齐操作，找到sentence1, sentence2,最长的句子，执行短句子补齐\n",
        "# 3. 定义一个tensor，把数据放里面\n",
        "\n",
        "class Collator:\n",
        "  def __init__(self, max_seq_len):\n",
        "    self.max_seq_len = max_seq_len\n",
        "  \n",
        "  def get_max_seq_len(self, ids_list):\n",
        "    cur_max_seq_len = max(len(input_id) for input_id in ids_list)\n",
        "    max_seq_len = min (self.max_seq_len, cur_max_seq_len)\n",
        "    return max_seq_len\n",
        "  \n",
        "  def pad_and_truncate(text_ids_list, max_seq_len):\n",
        "    input_ids = torch.zeros((len(text_ids_list), max_seq_len),dtype=torch.long)\n",
        "    for i, text_ids in enumerate(text_ids_list):\n",
        "      seq_len = min(len(text_ids), max_seq_len)\n",
        "      input_ids[i, :seq_len] = torch.tensor(text_ids[:seq_len],dtype=torch.long)\n",
        "    return input_ids\n",
        "\n",
        "  def __call__(self, examples):\n",
        "    # 1. 将元组中属于sentence1的放在一起，属于sentence2的放在一起，属于label的放在一起\n",
        "    text_ids_left_list, text_ids_right_list, labels_list = list(zip(*examples))\n",
        "    # 2.1 找到 text_ids_left_list, text_ids_right_list 最长的句子长度\n",
        "    max_text_left_length = self.get_max_seq_len(text_ids_left_list)\n",
        "    max_text_right_length = self.get_max_seq_len(text_ids_right_list)\n",
        "\n",
        "    # 2.2 执行短句子补齐, 3.定义一个tensor，把数据放里面\n",
        "    text_left_ids = self.pad_and_truncate(text_ids_left_list, max_text_left_length)\n",
        "    text_right_ids = self.pad_and_truncate(text_ids_right_list, max_text_right_length)\n",
        "    labels = torch.tensor(labels_list, dtype = torch.long)\n",
        "\n",
        "    data_list = [text_left_ids, text_right_ids, labels]\n",
        "    return data_list"
      ],
      "metadata": {
        "id": "vPyMg2fQCYzT"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "def build_dataloader(train_df, test_df, config, vocab):\n",
        "  X_train, y_train ,X_val, y_val, label2id, id2label = read_data(train_df, config['train_val_ratio'], vocab, mode='train')\n",
        "  X_test, y_test = read_data(test_df, config['train_val_ratio'], vocab, mode='test')\n",
        "\n",
        "  train_dataset = AFQMCDataset(X_train, y_train)\n",
        "  val_dataset = AFQMCDataset(X_val, y_val)\n",
        "  test_dataset = AFQMCDataset(X_test, y_test)\n",
        "  \n",
        "  collate_fn = Collator(config['max_seq_len'])\n",
        "\n",
        "  train_dataloader = DataLoader(dataset = train_dataset, batch_size = config['batch_size'], num_workers = 4, shuffle = True, collate_fn = collate_fn)\n",
        "  val_dataloader = DataLoader(dataset = val_dataset, batch_size = config['batch_size'], num_workers = 4, shuffle = False, collate_fn = collate_fn)\n",
        "  test_dataloader = DataLoader(dataset = test_dataset, batch_size = config['batch_size'], num_workers = 4, shuffle = False, collate_fn = collate_fn)\n",
        "\n",
        "  return id2label, test_dataloader, val_dataloader, train_dataloader"
      ],
      "metadata": {
        "id": "UckMgCUjF7u5"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label, test_dataloader, val_dataloader, train_dataloader = build_dataloader(train_df, test_df, config, token2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvgSVGf-Hxew",
        "outputId": "c6496d99-fe9e-4f49-996d-67550384d331"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocessing train data: 100%|██████████| 38650/38650 [00:13<00:00, 2964.86it/s]\n",
            "Preprocessing test data: 100%|██████████| 3861/3861 [00:01<00:00, 2957.27it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    }
  ]
}