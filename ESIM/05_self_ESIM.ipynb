{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_self_ESIM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faxwvxbp34mR",
        "outputId": "89de4905-8a25-40ff-95b8-584afb189662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr 23 09:09:37 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "#设置路径\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd2KAF6r4j-J",
        "outputId": "d2dd5a4b-27c9-40cd-888c-3c1916ce7479"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers==4.0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwtR4C9e5Vca",
        "outputId": "cb916624-aec1-4d8d-c841-c32963ba230c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.0.1\n",
            "  Downloading transformers-4.0.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 33.6 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 34.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 74.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (4.64.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.0.1) (3.0.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (7.1.2)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.49 tokenizers-0.9.4 transformers-4.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch==1.4.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNWZrNKAJFr_",
        "outputId": "c82a61ad-7764-4844-faa7-87378225ba45"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 6.5 kB/s \n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "config = {\n",
        "    'train_file_path':'/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/train.json',\n",
        "    'dev_file_path':'/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/dev.json',\n",
        "    'test_file_path':'/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/test.json',\n",
        "    'embedding_file_path':'/content/drive/MyDrive/Colab Notebooks/dataset/sgns.weibo.word.bz2',\n",
        "    'train_val_ratio':0.1,\n",
        "    'vocab_size':30000,\n",
        "    'batch_size':64,\n",
        "    # 从后面可以看出 64能容纳99%的句子长度\n",
        "    'max_seq_len':64,\n",
        "    'num_epochs':1,\n",
        "    'learning_rate':2e-5,\n",
        "    'logging_step':500,\n",
        "    'seed':2022,\n",
        "    'device': 'cpu'\n",
        "}\n",
        "if torch.cuda.is_available():\n",
        "  config['device'] = 'cuda'\n",
        "    \n",
        "def seed_everything(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  return seed\n",
        "\n",
        "seed_everything(config['seed'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mdTOeMT6U1w",
        "outputId": "dffc91cf-d012-44cb-890f-b2c6a74d224f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2022"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "def read_data(path):\n",
        "  sentence_a = []\n",
        "  sentence_b = []\n",
        "  labels = []\n",
        "  with open(path, 'r', encoding='utf8') as f:\n",
        "    for line in tqdm(f.readlines(), desc='Reading data'):\n",
        "      line = json.loads(line)\n",
        "      sentence_a.append(line['sentence1'])\n",
        "      sentence_b.append(line['sentence2'])\n",
        "      labels.append(int(line['label']))\n",
        "  \n",
        "  df = pd.DataFrame(zip(sentence_a, sentence_b, labels), columns=['text_a','text_b','labels'])\n",
        "  return df"
      ],
      "metadata": {
        "id": "v9eF7CtP5ado"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 复习一下zip函数:\n",
        "# 这里有两个元组()，每个元组有两个句子，一个label\n",
        "datas = [([1,2,3],[4,5,6],1),([777,888,999],[321,543,654],0)]\n",
        "# 取出列表中每个元素（元组）\n",
        "print(*datas)\n",
        "print(zip(*datas))\n",
        "# 把 datas 中的同一类别的放在一起\n",
        "print(list(zip(*datas)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkIjefdbLZnZ",
        "outputId": "6667cccc-a6b1-441a-b5dd-71b459ca40dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([1, 2, 3], [4, 5, 6], 1) ([777, 888, 999], [321, 543, 654], 0)\n",
            "<zip object at 0x7fcda1e1f820>\n",
            "[([1, 2, 3], [777, 888, 999]), ([4, 5, 6], [321, 543, 654]), (1, 0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = read_data(config['train_file_path'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6SDvo_BHzxr",
        "outputId": "c9ff2517-207d-414e-814d-feeea660991b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading data: 100%|██████████| 34334/34334 [00:00<00:00, 270944.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "u7g5tNarIggE",
        "outputId": "d50c384e-eb7a-4540-d24e-ff1109753329"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                text_a                                 text_b  labels\n",
              "0    蚂蚁借呗等额还款可以换成先息后本吗                             借呗有先息到期还本吗       0\n",
              "1           蚂蚁花呗说我违约一次                            蚂蚁花呗违约行为是什么       0\n",
              "2     帮我看一下本月花呗账单有没有结清                                 下月花呗账单       0\n",
              "3       蚂蚁借呗多长时间综合评估一次                                借呗得评估多久       0\n",
              "4  我的花呗账单是***，还款怎么是***  我的花呗，月结出来说让我还***元，我自己算了一下详细名单我应该还***元       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6b9dedf-528d-443c-8c4e-adea9343b244\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_a</th>\n",
              "      <th>text_b</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>蚂蚁借呗等额还款可以换成先息后本吗</td>\n",
              "      <td>借呗有先息到期还本吗</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>蚂蚁花呗说我违约一次</td>\n",
              "      <td>蚂蚁花呗违约行为是什么</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>帮我看一下本月花呗账单有没有结清</td>\n",
              "      <td>下月花呗账单</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>蚂蚁借呗多长时间综合评估一次</td>\n",
              "      <td>借呗得评估多久</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>我的花呗账单是***，还款怎么是***</td>\n",
              "      <td>我的花呗，月结出来说让我还***元，我自己算了一下详细名单我应该还***元</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6b9dedf-528d-443c-8c4e-adea9343b244')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d6b9dedf-528d-443c-8c4e-adea9343b244 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d6b9dedf-528d-443c-8c4e-adea9343b244');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_df = read_data(config['dev_file_path'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEQpzZ1qI7FB",
        "outputId": "05ea9fb2-9242-4951-a40e-5bd3835ef3ea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading data: 100%|██████████| 4316/4316 [00:00<00:00, 279077.11it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xYHahZ0BJBLJ",
        "outputId": "05b07aa7-adc2-4f0d-85b5-f77237cd8941"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             text_a                text_b  labels\n",
              "0         双十一花呗提额在哪              里可以提花呗额度       0\n",
              "1        花呗支持高铁票支付吗         为什么友付宝不支持花呗付款       0\n",
              "2  我的蚂蚁花呗支付金额怎么会有限制  我到支付宝实体店消费用花呗支付受金额限制       1\n",
              "3    为什么有花呗额度不能分期付款              花呗分期额度不足       0\n",
              "4       赠品不能设置用花呗付款            怎么不能花呗分期付款       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3137547f-6ebe-442e-8756-6613c0e00c93\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_a</th>\n",
              "      <th>text_b</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>双十一花呗提额在哪</td>\n",
              "      <td>里可以提花呗额度</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>花呗支持高铁票支付吗</td>\n",
              "      <td>为什么友付宝不支持花呗付款</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>我的蚂蚁花呗支付金额怎么会有限制</td>\n",
              "      <td>我到支付宝实体店消费用花呗支付受金额限制</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>为什么有花呗额度不能分期付款</td>\n",
              "      <td>花呗分期额度不足</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>赠品不能设置用花呗付款</td>\n",
              "      <td>怎么不能花呗分期付款</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3137547f-6ebe-442e-8756-6613c0e00c93')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3137547f-6ebe-442e-8756-6613c0e00c93 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3137547f-6ebe-442e-8756-6613c0e00c93');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_df.text_a.str.len() + train_df.text_b.str.len()).hist(bins = 20);\n",
        "(dev_df.text_a.str.len() + dev_df.text_b.str.len()).hist(bins = 20);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "8wo2ged9JNGI",
        "outputId": "1fcb3235-3c3a-40e6-f264-b27bb12d6183"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 64能容纳99%的句子长度\n",
        "(train_df.text_a.str.len() + train_df.text_b.str.len()).quantile(0.99)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpJl4UuwJmAC",
        "outputId": "931b25ed-5ec8-4d00-d494-19f70413c4dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64.0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 处理文件，生层词表放回关于train_df[train.json + dev.json],test_df\n",
        "from collections import Counter\n",
        "import jieba\n",
        "import bz2\n",
        "def preprocess(config):\n",
        "  def convert2df(file_path, dataset='train'):\n",
        "    sentence_a = []\n",
        "    sentence_b = []\n",
        "    labels = []\n",
        "    with open(file_path, 'r', encoding='utf8') as f:\n",
        "      for line in tqdm(f.readlines(), desc=f'Reading {dataset} data'):\n",
        "        line = json.loads(line)\n",
        "        sentence_a.append(line['sentence1'])\n",
        "        sentence_b.append(line['sentence2'])\n",
        "        if dataset != 'test':\n",
        "          labels.append(int(line['label']))\n",
        "        else:\n",
        "          labels.append(0)\n",
        "        # tokens为每次新加入的句子\n",
        "        tokens = list(jieba.cut(sentence_a[-1])) + list(jieba.cut(sentence_b[-1])) \n",
        "        # print('tokens:',tokens)\n",
        "        # tokens: ['蚂蚁', '花', '呗', '说', '我', '违约', '一次', '蚂蚁', '花', '呗', '违约', '行为', '是', '什么']\n",
        "        token_counter.update(tokens)\n",
        "    df = pd.DataFrame(zip(sentence_a,sentence_b,labels),columns=['text_a','text_b','labels'])\n",
        "    return df\n",
        "  \n",
        "  token_counter = Counter()\n",
        "\n",
        "  train_df = convert2df(config['train_file_path'],'train')\n",
        "  dev_df = convert2df(config['dev_file_path'],'dev')\n",
        "  test_df = convert2df(config['test_file_path'],'test')\n",
        "\n",
        "  train_df = train_df.append(dev_df)\n",
        "  vocab = set(token for token, _ in token_counter.most_common(config['vocab_size']))\n",
        "  # print('vocab:',vocab)\n",
        "  # vocab: {'城', '帮不上', '百度', '钱分', '会加分', '我晚', '手机短信'.......}\n",
        "  return train_df, test_df, vocab\n",
        "\n"
      ],
      "metadata": {
        "id": "64kVEP5GBNg6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df, vocab = preprocess(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmSHkwAyEwmI",
        "outputId": "e610ae79-6390-4fd4-e91a-c97bb22d5547"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rReading train data:   0%|          | 0/34334 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.826 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "Reading train data: 100%|██████████| 34334/34334 [00:07<00:00, 4772.66it/s]\n",
            "Reading dev data: 100%|██████████| 4316/4316 [00:01<00:00, 2612.97it/s]\n",
            "Reading test data: 100%|██████████| 3861/3861 [00:01<00:00, 2448.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TextCNN 词表对应成向量\n",
        "def get_embedding(vocab, embedding_file_path):\n",
        "  print('processing embedding file, please wait...')\n",
        "\n",
        "  token2embedding = {}\n",
        "\n",
        "  with bz2.open(embedding_file_path) as f:\n",
        "    token_vectors = f.readlines()\n",
        "    # print('token_vectors:',list(token_vectors[0:10]))\n",
        "    # token_vectors: [b'195202 300\\n', b'\\xef\\xbc\\x8c 0.094386 -0.200944 -0.030828 0.277130 ... 0.126182 -0.554329 -0.328050 \\n', b'......\\n'...]\n",
        "    meta_info = token_vectors[0].split()\n",
        "    # print('meta_info:',meta_info)\n",
        "    # meta_info: [b'195202', b'300']\n",
        "    print(f'{meta_info[0]} tokens in embedding file in total, vector size is {meta_info[-1]}')\n",
        "\n",
        "    for line in tqdm(token_vectors[1:]):\n",
        "      line = line.split()\n",
        "      token = line[0].decode('utf8')\n",
        "      # print('token:',token)\n",
        "      # token: ！\n",
        "      # token: 可以\n",
        "      # token: 等\n",
        "      # ...\n",
        "      vector = line[1:]\n",
        "      if token in vocab:\n",
        "        token2embedding[token] = [float(num) for num in vector]\n",
        "        # print('token2embedding[token]:',token2embedding[token])\n",
        "        # token2embedding[token]: [-0.124044, -0.053688, 0.157958, ... -0.127075, -0.020528, 0.032646]\n",
        "  #从4开始\n",
        "  token2idx = {token: idx for idx, token in enumerate(token2embedding.keys(),4)}\n",
        "  UNK, PAD, BOS, EOS = '<unk>', '<pad>', '<bos>', '<eos>'\n",
        "  token2idx[PAD] = 0 \n",
        "  token2idx[UNK] = 1\n",
        "  token2idx[BOS] = 2\n",
        "  token2idx[EOS] = 3\n",
        "  idx2token = {idx: token for token, idx in token2idx.items()}\n",
        "  idx2embedding = {token2idx[token]: embedding for token, embedding in token2embedding.items()}\n",
        "\n",
        "  idx2embedding[0] = [.0] * int(meta_info[-1])\n",
        "  idx2embedding[1] = [.0] * int(meta_info[-1])\n",
        "  idx2embedding[2] = np.random.random(int(meta_info[-1])).tolist()\n",
        "  idx2embedding[3] = np.random.random(int(meta_info[-1])).tolist()\n",
        "  emb_mat = [idx2embedding[idx] for idx in range(len(idx2embedding))]\n",
        "\n",
        "  return torch.tensor(emb_mat, dtype=torch.float), token2idx, len(vocab) + 4"
      ],
      "metadata": {
        "id": "U0PRXceWF3Fv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix, token2idx, config['vocab_size'] = get_embedding(vocab, config['embedding_file_path'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD-tn73jSuBi",
        "outputId": "3cc66c4d-138c-4945-c208-6bc852a0a1a3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing embedding file, please wait...\n",
            "b'195202' tokens in embedding file in total, vector size is b'300'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 195202/195202 [00:02<00:00, 65759.57it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "def tokenizer(sent, token2id):\n",
        "  # .get() 找到返回 token的id, 没找到就返回 1 1->UNK\n",
        "  ids = [token2id.get(token, 1) for token in jieba.cut(sent)]\n",
        "  return ids"
      ],
      "metadata": {
        "id": "qgfv519gw_JU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "df = pd.DataFrame(np.random.randn(4, 3), columns = ['col1', 'col2', 'col3'])\n",
        "df\n",
        "\n",
        "\tcol1\t  col2\t   col3\n",
        "0\t0.956880\t0.787811\t0.099237\n",
        "1\t0.413166\t-0.541869\t0.548336\n",
        "2\t0.951179\t0.113981\t1.130187\n",
        "3\t0.802346\t1.953860\t-2.062042\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "  print('i:',i,'row:',row)\n",
        "\n",
        "i: 0 row: col1    0.956880\n",
        "col2    0.787811\n",
        "col3    0.099237\n",
        "Name: 0, dtype: float64\n",
        "i: 1 row: col1    0.413166\n",
        "col2   -0.541869\n",
        "col3    0.548336\n",
        "Name: 1, dtype: float64\n",
        "i: 2 row: col1    0.951179\n",
        "col2    0.113981\n",
        "col3    1.130187\n",
        "Name: 2, dtype: float64\n",
        "i: 3 row: col1    0.802346\n",
        "col2    1.953860\n",
        "col3   -2.062042\n",
        "Name: 3, dtype: float64\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "  print('row[0]:',row[0])\n",
        "\n",
        "row[0]: 0.9568798249976214\n",
        "row[0]: 0.41316597459220283\n",
        "row[0]: 0.9511794577235149\n",
        "row[0]: 0.8023455023210482\n",
        "```"
      ],
      "metadata": {
        "id": "6-qPPSz-z9rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(data_df, train_val_ratio, token2id, mode = 'train'):\n",
        "  if mode == 'train':\n",
        "    X_train, y_train = defaultdict(list),[]\n",
        "    X_val, y_val = defaultdict(list),[]\n",
        "    num_val = int(len(data_df) * train_val_ratio)\n",
        "  else:\n",
        "    X_test, y_test = defaultdict(list),[]\n",
        "  \n",
        "  for i, row in tqdm(data_df.iterrows(), desc=f'Preprocessing {mode} data', total = len(data_df)):\n",
        "    text_left = row[0]\n",
        "    text_right = row[1]\n",
        "    label = row[2]\n",
        "\n",
        "    input_a = tokenizer(text_left, token2id = token2idx)\n",
        "    input_b = tokenizer(text_right, token2id = token2idx)\n",
        "    \n",
        "    if mode == 'train':\n",
        "      if i<num_val:\n",
        "        X_val['text_left'].append(input_a)\n",
        "        X_val['text_right'].append(input_b)\n",
        "        y_val.append(label)\n",
        "      else:\n",
        "        X_train['text_left'].append(input_a)\n",
        "        X_train['text_right'].append(input_b)\n",
        "        y_train.append(label)\n",
        "    else:\n",
        "      X_test['text_left'].append(input_a)\n",
        "      X_test['text_right'].append(input_b)\n",
        "      y_test.append(label)\n",
        "\n",
        "  if mode == 'train':\n",
        "    label2id = {label : i for i,label in enumerate(np.unique(y_train))}\n",
        "    id2label = {i : label for label, i in label2id.items()}\n",
        "    y_train = torch.tensor([label2id[label] for label in y_train], dtype= torch.long)\n",
        "    y_val = torch.tensor([label2id[label] for label in y_val], dtype= torch.long)\n",
        "    return X_train, y_train, X_val, y_val, label2id, id2label\n",
        "  else:\n",
        "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "    return X_test, y_test"
      ],
      "metadata": {
        "id": "l8ICD-VFxjym"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_val, y_val, label2id, id2label = read_data(train_df, config['train_val_ratio'], token2idx, mode='train')\n",
        "X_test, y_test = read_data(test_df, config['train_val_ratio'], token2idx, mode='test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJxabq4n4zYw",
        "outputId": "2012b1a4-375c-48a2-d178-a7b3d5f88c00"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocessing train data: 100%|██████████| 38650/38650 [00:09<00:00, 4053.00it/s]\n",
            "Preprocessing test data: 100%|██████████| 3861/3861 [00:00<00:00, 4163.65it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class AFQMCDataset(Dataset):\n",
        "  def __init__(self, x, y):\n",
        "    super(AFQMCDataset, self).__init__()\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    data = (self.x['text_left'][idx],\n",
        "         self.x['text_right'][idx],\n",
        "         self.y[idx]   \n",
        "            )\n",
        "    return data\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.y.size(0)#行数"
      ],
      "metadata": {
        "id": "4FM96AIK-19O"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "TextCNN中collete_fn函数\n",
        "def collete_fn(examples):\n",
        "    input_ids_list = []\n",
        "    labels =[]\n",
        "    for example in examples:\n",
        "        input_ids_list.append(example['input_ids'])\n",
        "        labels.append(example['label'])\n",
        "\n",
        "    # 对齐操作 -- 找到 input_ids_list 中 最长的 句子， 执行短句子补齐\n",
        "    # 1. 找到 input_ids_list 中 最长的 句子\n",
        "    max_length = max(len(input_ids) for input_ids in input_ids_list) \n",
        "    # 2. 定义一个 input_ids_tensor, 我们要把 每个 input_ids 放入 tensor 中\n",
        "    input_ids_tensor = torch.zeros((len(labels), max_length), dtype=torch.long)\n",
        "    for i, input_ids in enumerate(input_ids_list):\n",
        "        # 得到当前句子的长度\n",
        "        seq_len = len(input_ids)\n",
        "        # 第i个句子，填充 seq_len 这么长\n",
        "        input_ids_tensor[i, :seq_len] = torch.tensor(input_ids, dtype=torch.long)\n",
        "\n",
        "    return {\n",
        "        'input_ids' : input_ids_tensor,\n",
        "        'labels' : torch.tensor(labels, dtype=torch.long)\n",
        "    }\n",
        "```"
      ],
      "metadata": {
        "id": "f42aK8fiAagL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# __call__方法的调用\n",
        "class MyClass():\n",
        "  def __call__(self):\n",
        "    print('__call__方法被调用')\n",
        "    return 'done'"
      ],
      "metadata": {
        "id": "SngM5VBdATU8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 类实例化\n",
        "obj = MyClass()"
      ],
      "metadata": {
        "id": "mxbuYVYqBhnk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 实例化的对象 当作函数用\n",
        "res = obj()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mru9AQZJBlEr",
        "outputId": "15f6e15c-e34a-4f10-a476-09772c9dd782"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__call__方法被调用\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 从 AFQMCDataset 输出的 data  = (sentence1, sentence2, label])\n",
        "# 1. 将元组中属于sentence1的放在一起，属于sentence2的放在一起，属于label的放在一起\n",
        "# 2. 对齐操作，找到sentence1, sentence2,最长的句子，执行短句子补齐\n",
        "# 3. 定义一个tensor，把数据放里面\n",
        "\n",
        "class Collator:\n",
        "  def __init__(self, max_seq_len):\n",
        "    self.max_seq_len = max_seq_len\n",
        "  \n",
        "  def get_max_seq_len(self, ids_list):\n",
        "    cur_max_seq_len = max(len(input_id) for input_id in ids_list)\n",
        "    max_seq_len = min (self.max_seq_len, cur_max_seq_len)\n",
        "    return max_seq_len\n",
        "\n",
        "  #当某个方法不需要用到对象中的任何资源(没有self),将这个方法改为一个静态方法, 加一个@staticmethod。\n",
        "  #加上之后, 这个方法就和普通的函数没有什么区别了, 只不过写在了一个类中, 可以使用这个类的对象调用,\n",
        "  @staticmethod\n",
        "  def pad_and_truncate(text_ids_list, max_seq_len):\n",
        "    input_ids = torch.zeros((len(text_ids_list), max_seq_len),dtype=torch.long)\n",
        "    for i, text_ids in enumerate(text_ids_list):\n",
        "      seq_len = min(len(text_ids), max_seq_len)\n",
        "      input_ids[i, :seq_len] = torch.tensor(text_ids[:seq_len],dtype=torch.long)\n",
        "    return input_ids\n",
        "\n",
        "  def __call__(self, examples):\n",
        "    # 1. 将元组中属于sentence1的放在一起，属于sentence2的放在一起，属于label的放在一起\n",
        "    text_ids_left_list, text_ids_right_list, labels_list = list(zip(*examples))\n",
        "    # 2.1 找到 text_ids_left_list, text_ids_right_list 最长的句子长度\n",
        "    max_text_left_length = self.get_max_seq_len(text_ids_left_list)\n",
        "    max_text_right_length = self.get_max_seq_len(text_ids_right_list)\n",
        "\n",
        "    # 2.2 执行短句子补齐, 3.定义一个tensor，把数据放里面\n",
        "    text_left_ids = self.pad_and_truncate(text_ids_left_list, max_text_left_length)\n",
        "    text_right_ids = self.pad_and_truncate(text_ids_right_list, max_text_right_length)\n",
        "    labels = torch.tensor(labels_list, dtype = torch.long)\n",
        "\n",
        "    data_list = [text_left_ids, text_right_ids, labels]\n",
        "    return data_list"
      ],
      "metadata": {
        "id": "vPyMg2fQCYzT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "def build_dataloader(train_df, test_df, config, vocab):\n",
        "  X_train, y_train ,X_val, y_val, label2id, id2label = read_data(train_df, config['train_val_ratio'], vocab, mode='train')\n",
        "  X_test, y_test = read_data(test_df, config['train_val_ratio'], vocab, mode='test')\n",
        "\n",
        "  train_dataset = AFQMCDataset(X_train, y_train)\n",
        "  val_dataset = AFQMCDataset(X_val, y_val)\n",
        "  test_dataset = AFQMCDataset(X_test, y_test)\n",
        "  \n",
        "  collate_fn = Collator(config['max_seq_len'])\n",
        "\n",
        "  train_dataloader = DataLoader(dataset = train_dataset, batch_size = config['batch_size'], num_workers = 4, shuffle = True, collate_fn = collate_fn)\n",
        "  val_dataloader = DataLoader(dataset = val_dataset, batch_size = config['batch_size'], num_workers = 4, shuffle = False, collate_fn = collate_fn)\n",
        "  test_dataloader = DataLoader(dataset = test_dataset, batch_size = config['batch_size'], num_workers = 4, shuffle = False, collate_fn = collate_fn)\n",
        "\n",
        "  return id2label, test_dataloader, val_dataloader, train_dataloader"
      ],
      "metadata": {
        "id": "UckMgCUjF7u5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label, test_dataloader, val_dataloader, train_dataloader = build_dataloader(train_df, test_df, config, token2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvgSVGf-Hxew",
        "outputId": "fea0397f-852e-44b2-d6e8-923dd53b6055"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocessing train data: 100%|██████████| 38650/38650 [00:09<00:00, 4055.28it/s]\n",
            "Preprocessing test data: 100%|██████████| 3861/3861 [00:00<00:00, 4109.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in train_dataloader:\n",
        "  print('dataloader中一个batch数据为（左+右+label）:',i)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeJ8-aPCtn3y",
        "outputId": "706a36f8-7793-476d-b3a6-b910d6b264a2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataloader中一个batch数据为（左+右+label）: [tensor([[ 272, 1359,  410,  ...,    0,    0,    0],\n",
            "        [2493, 1448, 1359,  ...,    0,    0,    0],\n",
            "        [ 190, 1412,   22,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [2095,  189, 1226,  ...,    0,    0,    0],\n",
            "        [ 925,  981,  407,  ...,    0,    0,    0],\n",
            "        [2493, 1448, 1359,  ...,    0,    0,    0]]), tensor([[ 410,  272, 1359,  ...,    0,    0,    0],\n",
            "        [2493, 1448, 1359,  ...,    0,    0,    0],\n",
            "        [  22,    5, 1448,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [  22,    5,  272,  ...,    0,    0,    0],\n",
            "        [ 272, 1359,  925,  ...,    0,    0,    0],\n",
            "        [ 410,  130, 1448,  ..., 1090,   21,   69]]), tensor([1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
            "        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_iterator = tqdm(val_dataloader, desc='Test_item', total=len(val_dataloader))\n",
        "for batch in val_iterator:\n",
        "  print('batch:',batch)\n",
        "  i=0\n",
        "  for item in batch:\n",
        "    print('item:',item)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzAIHuyr1QwL",
        "outputId": "d715e375-d79f-4429-e04e-de7bd51b9e15"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test_item:   0%|          | 0/121 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch: [tensor([[2493, 1448, 1359,  ...,    0,    0,    0],\n",
            "        [2493,  272, 1359,  ...,    0,    0,    0],\n",
            "        [ 407,   22,   70,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [ 272, 1359,  607,  ...,    0,    0,    0],\n",
            "        [   1, 1359,   16,  ...,    0,    0,    0],\n",
            "        [ 272, 1359, 4406,  ...,    0,    0,    0]]), tensor([[1448, 1359,   15,  ...,    0,    0,    0],\n",
            "        [2493,  272, 1359,  ...,    0,    0,    0],\n",
            "        [ 111,   69,  272,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [1090, 1090, 1090,  ...,    0,    0,    0],\n",
            "        [   1,  272, 1359,  ...,  703,   38,    0],\n",
            "        [ 272, 1359,  272,  ...,    0,    0,    0]]), tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
            "item: tensor([[2493, 1448, 1359,  ...,    0,    0,    0],\n",
            "        [2493,  272, 1359,  ...,    0,    0,    0],\n",
            "        [ 407,   22,   70,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [ 272, 1359,  607,  ...,    0,    0,    0],\n",
            "        [   1, 1359,   16,  ...,    0,    0,    0],\n",
            "        [ 272, 1359, 4406,  ...,    0,    0,    0]])\n",
            "item: tensor([[1448, 1359,   15,  ...,    0,    0,    0],\n",
            "        [2493,  272, 1359,  ...,    0,    0,    0],\n",
            "        [ 111,   69,  272,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [1090, 1090, 1090,  ...,    0,    0,    0],\n",
            "        [   1,  272, 1359,  ...,  703,   38,    0],\n",
            "        [ 272, 1359,  272,  ...,    0,    0,    0]])\n",
            "item: tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "def evaluation(config, model, val_dataloader):\n",
        "  model.eval()\n",
        "  preds = []\n",
        "  labels = []\n",
        "  val_loss = 0.\n",
        "  val_iterator = tqdm(val_dataloader, desc='Evaluation', total=len(val_dataloader))\n",
        "  with torch.no_grad():\n",
        "    for batch in val_iterator:\n",
        "      labels.append(batch[-1])\n",
        "      batch = [item.to(config['device']) for item in batch]\n",
        "      loss, logits = model(batch)[:2]\n",
        "\n",
        "      val_loss += loss.item()\n",
        "      # 返回逻辑值最大的位置，要么0，要么1\n",
        "      preds.append(logits.argmax(dim=-1).detach().cpu())\n",
        "\n",
        "  avg_val_loss = val_loss / len(val_dataloader)\n",
        "  labels = torch.cat(labels, dim=0).numpy()\n",
        "  preds = torch.cat(preds, dim=0).numpy()\n",
        "  f1 = f1_score(labels, preds, average='macro')\n",
        "\n",
        "  acc = accuracy_score(labels, preds)\n",
        "\n",
        "  return avg_val_loss, f1, acc"
      ],
      "metadata": {
        "id": "Wgjrz85kt48Z"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import trange\n",
        "from transformers import AdamW\n",
        "\n",
        "def train(model, config, id2label, train_dataloader, val_dataloader):\n",
        "  optimizer = AdamW(model.parameters(), lr = config['learning_rate'])\n",
        "  epoch_iterator = trange(config['num_epochs'])\n",
        "\n",
        "  global_steps = 0\n",
        "  train_loss = 0.\n",
        "  logging_loss = 0.\n",
        "  model.to(config['device'])\n",
        "  \n",
        "  for epoch in epoch_iterator:\n",
        "    train_iterator = tqdm(train_dataloader, desc='Training', total=len(train_dataloader))\n",
        "    model.train()\n",
        "    for batch in train_iterator:\n",
        "\n",
        "      batch =  [item.to(config['device']) for item in batch]\n",
        "      loss = model(batch)[0]\n",
        "\n",
        "      model.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      train_loss += loss.item()\n",
        "      global_steps += 1\n",
        "\n",
        "      if global_steps % config['logging_step'] == 0:\n",
        "        print_train_loss = (train_loss - logging_loss) / config['logging_step']\n",
        "        logging_loss = train_loss\n",
        "\n",
        "        avg_val_loss, f1, acc = evaluation(config, model, val_dataloader)\n",
        "\n",
        "        print_log = f'>>>traing loss:{print_train_loss: .5f}, valid loss:{avg_val_loss: .5f}, valid f1 score:{f1: .5f}, valid acc:{acc: .5f}'\n",
        "\n",
        "        print(print_log)\n",
        "        model.train()\n",
        "  return model"
      ],
      "metadata": {
        "id": "NYMC8N5W4yoK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(config, id2label, model, test_dataloader):\n",
        "  test_iterator = tqdm(test_dataloader, desc='Predicting', total=len(test_dataloader))\n",
        "  model.eval()\n",
        "  test_preds = []\n",
        "  with torch.no_grad():\n",
        "    for batch in test_iterator:\n",
        "      batch = [item.to(config['device']) for item in batch]\n",
        "      logits = model(batch)[1]\n",
        "      test_preds.append(logits.argmax(dim=-1).detach().cpu())\n",
        "  test_preds = torch.cat(test_preds, dim = 0).numpy()\n",
        "  test_preds = [id2label[id_] for id_ in test_preds]\n",
        "  return test_preds"
      ],
      "metadata": {
        "id": "-Z4-MtoB9qQP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 预备知识"
      ],
      "metadata": {
        "id": "lfox0JdZHzKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义一个[2,3,4]的tensor -> [batch_size, seq_len, embedding_dim]  一个batch有两个句子，每个句子3个词，每个词的维度为4\n",
        "a = torch.tensor([[[2., 2., 2., 2.],[3., 3., 3., 3.],[4., 4., 4., 4.]],[[5., 5., 5., 5.],[6., 6., 6., 6.],[7., 7., 7., 7.]]])\n",
        "print(a)\n",
        "print(a.size())"
      ],
      "metadata": {
        "id": "lekcYK7VHyl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e857794-6589-4c88-88f0-a4e2dea5a923"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[2., 2., 2., 2.],\n",
            "         [3., 3., 3., 3.],\n",
            "         [4., 4., 4., 4.]],\n",
            "\n",
            "        [[5., 5., 5., 5.],\n",
            "         [6., 6., 6., 6.],\n",
            "         [7., 7., 7., 7.]]])\n",
            "torch.Size([2, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [2,1,4]的tensor\n",
        "# torch.Tensor是一种包含单一数据类型元素的多维矩阵，torch.Tensor是默认的tensor类型（torch.FlaotTensor）的简称。\n",
        "# torch.ByteTensor 是 CPU tensor, 8-bit integer (unsigned)\n",
        "ones = torch.ByteTensor([[[1, 1, 0, 0]],[[0, 1, 1, 0]]])\n",
        "print(ones.size())"
      ],
      "metadata": {
        "id": "fVxkqiQiItQ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad751530-6556-4a14-fb99-244cecd33666"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 相当于将词向量某些维度清零\n",
        "print(ones * a) # 首先，ones. 从[2,1,4] 变成 [2,3,4] （填充） 再与a中逐个元素相乘\n",
        "print((ones * a).size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKyKg9NaLHOE",
        "outputId": "397f3427-b9f0-42e3-f578-9143a56d507c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[2., 2., 0., 0.],\n",
            "         [3., 3., 0., 0.],\n",
            "         [4., 4., 0., 0.]],\n",
            "\n",
            "        [[0., 5., 5., 0.],\n",
            "         [0., 6., 6., 0.],\n",
            "         [0., 7., 7., 0.]]])\n",
            "torch.Size([2, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## masked fill 方法"
      ],
      "metadata": {
        "id": "ie4SqRHVb5Mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [2, 3, 1]\n",
        "mask = torch.ByteTensor([[[1],[1],[0]],[[0],[1],[1]]])\n",
        "print(mask)\n",
        "print(mask.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hjnj8kn1b8zA",
        "outputId": "eb89a52e-c80e-42f8-8369-c23810c8a5a2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1],\n",
            "         [1],\n",
            "         [0]],\n",
            "\n",
            "        [[0],\n",
            "         [1],\n",
            "         [1]]], dtype=torch.uint8)\n",
            "torch.Size([2, 3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "a:\n",
        "tensor([[[2., 2., 2., 2.],\n",
        "    [3., 3., 3., 3.],\n",
        "    [4., 4., 4., 4.]],\n",
        "\n",
        "    [[5., 5., 5., 5.],\n",
        "    [6., 6., 6., 6.],\n",
        "    [7., 7., 7., 7.]]])\n",
        "\n",
        "mask:\n",
        "tensor([[[1],\n",
        "    [1],\n",
        "    [0]],\n",
        "\n",
        "    [[0],\n",
        "    [1],\n",
        "    [1]]], dtype=torch.uint8)\n",
        "```"
      ],
      "metadata": {
        "id": "2u6XC1WJdbYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a [2,3,4] mask[2,3,1]\n",
        "# 是将 mask 中 为1 的元素所在的索引，在 a 中 相同索引处替换为 value值\n",
        "# 把某个词向量给mask掉\n",
        "b = a.masked_fill(mask, value = torch.tensor(-1e7))\n",
        "print(b)\n",
        "print(b.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og5QgPilc6wo",
        "outputId": "6371fffd-eef0-4bd3-cfac-381921a48185"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-1.0000e+07, -1.0000e+07, -1.0000e+07, -1.0000e+07],\n",
            "         [-1.0000e+07, -1.0000e+07, -1.0000e+07, -1.0000e+07],\n",
            "         [ 4.0000e+00,  4.0000e+00,  4.0000e+00,  4.0000e+00]],\n",
            "\n",
            "        [[ 5.0000e+00,  5.0000e+00,  5.0000e+00,  5.0000e+00],\n",
            "         [-1.0000e+07, -1.0000e+07, -1.0000e+07, -1.0000e+07],\n",
            "         [-1.0000e+07, -1.0000e+07, -1.0000e+07, -1.0000e+07]]])\n",
            "torch.Size([2, 3, 4])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:41: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "``` \n",
        "ones:\n",
        "tensor([[[1, 1, 0, 0]],\n",
        "    [[0, 1, 1, 0]]])\n",
        "```"
      ],
      "metadata": {
        "id": "vcY4I42-gtdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 同理，可以用[2, 1, 4] mask掉 [2, 3, 4]\n",
        "# 把 mask 改成 ones\n",
        "mask = ones #[2, 1, 4]\n",
        "b= a.masked_fill(mask, value = torch.tensor(-1e7))\n",
        "print(b)\n",
        "print(b.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyOsoRhBfuGm",
        "outputId": "36f83084-4aa6-4d6e-ffd4-f5147e4da4bf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-1.0000e+07, -1.0000e+07,  2.0000e+00,  2.0000e+00],\n",
            "         [-1.0000e+07, -1.0000e+07,  3.0000e+00,  3.0000e+00],\n",
            "         [-1.0000e+07, -1.0000e+07,  4.0000e+00,  4.0000e+00]],\n",
            "\n",
            "        [[ 5.0000e+00, -1.0000e+07, -1.0000e+07,  5.0000e+00],\n",
            "         [ 6.0000e+00, -1.0000e+07, -1.0000e+07,  6.0000e+00],\n",
            "         [ 7.0000e+00, -1.0000e+07, -1.0000e+07,  7.0000e+00]]])\n",
            "torch.Size([2, 3, 4])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:41: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ESIM \n",
        "## Enhanced LSTM for Natural Language Inference"
      ],
      "metadata": {
        "id": "NxMZp4BGiwQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = {\n",
        "    'embedding': embedding_matrix, #torch.Size([5251,300])\n",
        "    'freeze_emb': True,\n",
        "    'hidden_size': 256,\n",
        "    'dropout': 0.3,\n",
        "    'num_layers': 2,\n",
        "    'concat_layers': True,\n",
        "    'rnn_type': 'lstm',\n",
        "    'num_labels': len(id2label)\n",
        "}"
      ],
      "metadata": {
        "id": "3eZUHxRBiz58"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 一些参数\n",
        "```\n",
        "B: batch_size\n",
        "L = 'inputs left'  sequence length\n",
        "R = 'inputs right'  sequence length\n",
        "D = embedding size\n",
        "H = hidden size\n",
        "```"
      ],
      "metadata": {
        "id": "5FYVfzkKA6xX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class RNNDropout(nn.Dropout):\n",
        "  # 将词向量 某些维度 清0\n",
        "  # sequences_batch [B, L, D] (和query、doc一样)\n",
        "  def forward(self, sequences_batch):\n",
        "    # ones [B, D]\n",
        "    ones = sequences_batch.data.new_ones(sequences_batch.shape[0], sequences_batch.shape[-1])\n",
        "    # 随机mask ones\n",
        "    # dropout_mask [B, D] ones后面是dropout API的参数  \n",
        "    # p – probability of an element to be zeroed. Default: 0.5\n",
        "    # training – apply dropout if is True. Default: True\n",
        "    # inplace – If set to True, will do this operation in-place[将原地执行此操作]. Default: False\n",
        "    dropout_mask = nn.functional.dropout(ones, self.p, self.training, inplace=False)\n",
        "    # unsqueeze(1)增加一个维度\n",
        "    return dropout_mask.unsqueeze(1) * sequences_batch\n"
      ],
      "metadata": {
        "id": "NROHeernAMmO"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "class StackedBRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers,\n",
        "         dropout_rate = 0, dropout_output = False,\n",
        "         rnn_type = nn.LSTM, concat_layers = False):\n",
        "    \n",
        "    super().__init__()\n",
        "    self.dropout_output = dropout_output\n",
        "    self.dropout_rate = dropout_rate\n",
        "    self.num_layers = num_layers\n",
        "    self.concat_layers = concat_layers\n",
        "    self.rnns = nn.ModuleList()\n",
        "    # 共有2层lstm\n",
        "    for i in range(num_layers):\n",
        "      input_size = input_size if i == 0 else 2*hidden_size\n",
        "      self.rnns.append(rnn_type(input_size, hidden_size, num_layers=1, bidirectional=True))\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x (B, L, D)[此时不能输入到LSTM中] -> (L, B, D)\n",
        "    x= x.transpose(0, 1)\n",
        "    outputs = [x]\n",
        "    for i in range(self.num_layers):\n",
        "      rnn_input = outputs[-1]\n",
        "\n",
        "      if self.dropout_rate > 0:\n",
        "        rnn_input = F.dropout(rnn_input, p=self.dropout_rate, training = self.training)\n",
        "\n",
        "\n",
        "      # self.rnn[i](rnn_input) (output, (h_n, c_n))\n",
        "      rnn_output = self.rnns[i](rnn_input)[0]\n",
        "      outputs.append(rnn_output)\n",
        "    # outputs [x, output0, output1]\n",
        "    if self.concat_layers:\n",
        "      output = torch.cat(outputs[1:], 2)\n",
        "    else:\n",
        "      output = outputs[-1]\n",
        "    # output (L, B, D) -> (B, L, D)\n",
        "    output = output.transpose(0, 1)\n",
        "\n",
        "    if self.dropout_output and self.dropout_rate > 0:\n",
        "      output = F.dropout(output, p = self.dropout_rate, training = self.training)\n",
        "      \n",
        "    # 进行 transpose之后，tensor在内存中不连续， contiguous将output内存连续\n",
        "    return output.contiguous()"
      ],
      "metadata": {
        "id": "Oi8C7HTgF7Lq"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BidirectionalAttention(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # 维度        \n",
        "    # v1 [B, L, H]\n",
        "    # v1_mask [B, L]\n",
        "    # v2 [B, R, H]\n",
        "    # v2_mask [B, R]\n",
        "  def forward(self, v1, v1_mask, v2, v2_mask):\n",
        "    # v2:句子a v1:句子b \n",
        "\n",
        "    # bmm 矩阵相乘\n",
        "    # 计算两个tensor的矩阵乘法，torch.bmm(a,b)\n",
        "    # tensor a 的size为(b,h,w) tensor b的size为(b,w,m), 输出（b,h,m）\n",
        "    # 注意两个tensor的维度必须为3.\n",
        "\n",
        "    # 1.计算矩阵相似度\n",
        "    # similarity_matrix [B, L, R]\n",
        "    similarity_matrix = v1.bmm(v2.transpose(2,1).contiguous())\n",
        "\n",
        "    # 2.计算attention时没有必要计算pad=0, 要进行mask操作 3.进行softmax\n",
        "    # 将similarity_matrix v1中pad对应的权重给mask\n",
        "    # [B, L, R]\n",
        "    # v1_mask.unsqueeze(2) 给v1_mask增加一维\n",
        "    # 在第一维 L 进行softmax\n",
        "    v2_v1_attn = F.softmax(similarity_matrix.masked_fill(\n",
        "          v1_mask.unsqueeze(2),-1e8), dim = 1)\n",
        "      \n",
        "    v1_v2_attn = F.softmax(similarity_matrix.masked_fill(\n",
        "          v2_mask.unsqueeze(1),-1e8), dim = 2)\n",
        "      \n",
        "    # 4.计算attention\n",
        "    # [B, L, R] @ [B, R, H] 矩阵运算\n",
        "    # 句子a 对b的影响 [B, L, H]\n",
        "    # attented_v1 [B, L, H]\n",
        "    attented_v1 = v1_v2_attn.bmm(v2)\n",
        "\n",
        "    # 句子b 对a的影响 \n",
        "    # v2_v1_attn [B, L, R] -> [B, R, L] @[B, L, H] -> [B, R, H]\n",
        "    # attented_v2 [B, R, H]\n",
        "    attented_v2 = v2_v1_attn.transpose(1,2).bmm(v1)\n",
        "\n",
        "    # 使用attented_v1 将v1对应的pad填充为0\n",
        "    # 使用attented_v2 将v2对应的pad填充为0\n",
        "    # v1/2_mask 随意增加一个维度进行mask\n",
        "    attented_v1.masked_fill(v1_mask.unsqueeze(2), 0)\n",
        "    attented_v2.masked_fill(v2_mask.unsqueeze(2), 0)\n",
        "    return attented_v1, attented_v2"
      ],
      "metadata": {
        "id": "ViVQT1nIpF6Q"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ESIM(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "\n",
        "    rnn_mapping = {'lstm': nn.LSTM, 'gru': nn.GRU}\n",
        "    self.embedding = nn.Embedding.from_pretrained(config['embedding'], freeze = config['freeze_emb'])\n",
        "    self.rnn_dropout = RNNDropout(p = config['dropout'])\n",
        "    rnn_size = config['hidden_size']\n",
        "\n",
        "    if config['concat_layers']:\n",
        "      # 取整除赋值运算符\tc //= a 等效于 c = c // a\n",
        "      rnn_size //= config['num_layers']\n",
        "    self.input_encoding = StackedBRNN(input_size = config['embedding'].size(1),\n",
        "                      hidden_size = rnn_size // 2,\n",
        "                      num_layers = config['num_layers'],\n",
        "                      rnn_type = rnn_mapping[config['rnn_type']],\n",
        "                      concat_layers = config['concat_layers'])\n",
        "    \n",
        "\n",
        "    self.attention = BidirectionalAttention()\n",
        "\n",
        "    self.projection = nn.Sequential(\n",
        "        nn.Linear(4 * config['hidden_size'], config['hidden_size']),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.composition = StackedBRNN(input_size= config['hidden_size'],\n",
        "                   hidden_size= rnn_size // 2,\n",
        "                   num_layers = config['num_layers'],\n",
        "                   rnn_type = rnn_mapping[config['rnn_type']],\n",
        "                   concat_layers = config['concat_layers'])\n",
        "    \n",
        "    self.classification = nn.Sequential(\n",
        "        nn.Dropout(p = config['dropout']),\n",
        "        nn.Linear(4 * config['hidden_size'], config['hidden_size']),\n",
        "        nn.Tanh(),\n",
        "        nn.Dropout(p = config['dropout']))\n",
        "    self.out = nn.Linear(config['hidden_size'], config['num_labels'])\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    # inputs: [sentence1_tensor, sentence2_tensor, labels_tensor]\n",
        "    # B: batch_size\n",
        "    # L = 'inputs left'  sequence length\n",
        "    # R = 'inputs right'  sequence length\n",
        "    # D = embedding size\n",
        "    # H = hidden size \n",
        "\n",
        "    # query: sentence1_tensor\n",
        "    # doc: sentence2_tensor\n",
        "   \n",
        "    # query [B, L]\n",
        "    # doc [B, R]   \n",
        "    query, doc = inputs[0].long(), inputs[1].long()\n",
        "\n",
        "    # 判断 query，doc中的每一个数是不是0， 是1则表示该位置是pad\n",
        "    # query：[2,3,4,5,0,0,0] -> query_mask：[0,0,0,0,1,1,1]\n",
        "    # query_mask [B, L]\n",
        "    # doc_mask [B, R]\n",
        "    query_mask = (query == 0)\n",
        "    doc_mask = (doc == 0)\n",
        "\n",
        "    # query [B, L, D]\n",
        "    # doc [B, R, D]\n",
        "    query = self.embedding(query)\n",
        "    doc = self.embedding(doc)\n",
        "\n",
        "    # query [B, L, D]\n",
        "    # doc [B, R, D]\n",
        "    query = self.rnn_dropout(query)\n",
        "    doc = self.rnn_dropout(doc)\n",
        "\n",
        "    # query [B, L, H]\n",
        "    # doc [B, R, H]\n",
        "    query = self.input_encoding(query)\n",
        "    doc = self.input_encoding(doc)\n",
        "\n",
        "\n",
        "    # 1.计算矩阵相似度\n",
        "    # 2.计算attention时没有必要计算pad=0（补齐时，填充为0的单元）, 要进行mask操作\n",
        "    # 3.进行softmax\n",
        "    # 4.计算attention\n",
        "\n",
        "    # query [B, L, H]\n",
        "    # query_mask [B, L]\n",
        "    # doc [B, R, H]\n",
        "    # doc_mask [B, R]\n",
        "    attended_query, attended_doc = self.attention(query, query_mask, doc, doc_mask)\n",
        "\n",
        "    # enhanced_query [B, L, 4*h]\n",
        "    # enhanced_doc [B, R, 4*h]\n",
        "    # dim = -1 按倒数第一维cat\n",
        "    enhanced_query = torch.cat([query,attended_query,\n",
        "                   query-attended_query,\n",
        "                   query*attended_query],dim = -1)\n",
        "    enhanced_doc = torch.cat([doc,attended_doc,\n",
        "                  doc-attended_doc,\n",
        "                  doc*attended_doc],dim = -1)\n",
        "    # projected_query [B, L, H]\n",
        "    # projected_doc [B, R, H]\n",
        "    projected_query = self.projection(enhanced_query)\n",
        "    projected_doc = self.projection(enhanced_doc)\n",
        "\n",
        "    query = self.composition(projected_query)\n",
        "    doc = self.composition(projected_doc)\n",
        "\n",
        "    # query_mask， doc_mask. 判断 query，doc中的每一个数是不是0， 是1则表示该位置是pad\n",
        "    # reverse_query_mask 0的位置代表pad\n",
        "    # reverse_query_mask [B, L]\n",
        "    # reverse_doc_mask [B, R]\n",
        "    reverse_query_mask = 1. - query_mask.float()\n",
        "    reverse_doc_mask = 1. - doc_mask.float()\n",
        "\n",
        "    # torch.sum(input, dim, keepdim=False, *, dtype=None) → Tensor\n",
        "    # Returns the sum of each row of the input tensor in the given dimension dim. If dim is a list of dimensions, reduce over all of them.\n",
        "    # If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s).\n",
        "    query_avg = torch.sum(query * reverse_query_mask.unsqueeze(2),dim = 1) / (torch.sum(reverse_query_mask, dim = 1, keepdim= True) + 1e-8)\n",
        "    doc_avg = torch.sum(doc * reverse_doc_mask.unsqueeze(2),dim = 1) / (torch.sum(reverse_doc_mask, dim = 1, keepdim= True) + 1e-8)\n",
        "       \n",
        "    # 防止取出pad\n",
        "    query =query.masked_fill(query_mask.unsqueeze(2), -1e7)\n",
        "    doc = doc.masked_fill(doc_mask.unsqueeze(2), -1e7)\n",
        "\n",
        "    query_max, _ = query.max(dim = 1)\n",
        "    doc_max, _ = doc.max(dim = 1)\n",
        "\n",
        "    # v [B, 4*H]\n",
        "    v = torch.cat([query_avg, query_max, doc_avg, doc_max], dim = -1)\n",
        "\n",
        "\n",
        "    # hidden [B, H]\n",
        "    hidden = self.classification(v)\n",
        "\n",
        "    out = self.out(hidden)\n",
        "    outputs = (out, )\n",
        "\n",
        "    if len(inputs) == 3:\n",
        "      loss_fct = nn.CrossEntropyLoss()\n",
        "      loss = loss_fct(out, inputs[-1])\n",
        "      outputs = (loss, )+ outputs\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "1EDATCZXPJMf"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch.sum\n",
        "```\n",
        "torch.sum(input, dim, keepdim=False, *, dtype=None) → Tensor\n",
        ">>> a = torch.randn(4, 4)\n",
        ">>> a\n",
        "    tensor([[ 0.0569, -0.2475,  0.0737, -0.3429],\n",
        "        [-0.2993,  0.9138,  0.9337, -1.6864],\n",
        "        [ 0.1132,  0.7892, -0.1003,  0.5688],\n",
        "        [ 0.3637, -0.9906, -0.4752, -1.5197]])\n",
        ">>> torch.sum(a, 1)\n",
        "tensor([-0.4598, -0.1381,  1.3708, -2.6217])\n",
        "-0.4598 为第一行加起来\n",
        "```"
      ],
      "metadata": {
        "id": "AHIfOrgSZ3Kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ESIM(model_config)"
      ],
      "metadata": {
        "id": "Y8xsFB3Qep6F"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ESIM_model = train(model, config, id2label, train_dataloader, val_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfpmmqe3fLXe",
        "outputId": "709fb338-93ba-4b17-a5b0-8c5a4f8c8033"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Training:   0%|          | 0/484 [00:00<?, ?it/s]\u001b[A\n",
            "Training:   0%|          | 1/484 [00:00<01:41,  4.77it/s]\u001b[A\n",
            "Training:   1%|          | 4/484 [00:00<00:32, 14.59it/s]\u001b[A\n",
            "Training:   2%|▏         | 8/484 [00:00<00:22, 21.62it/s]\u001b[A\n",
            "Training:   2%|▏         | 12/484 [00:00<00:17, 26.67it/s]\u001b[A\n",
            "Training:   3%|▎         | 16/484 [00:00<00:15, 30.18it/s]\u001b[A\n",
            "Training:   4%|▍         | 20/484 [00:00<00:15, 30.11it/s]\u001b[A\n",
            "Training:   5%|▍         | 24/484 [00:00<00:14, 31.70it/s]\u001b[A\n",
            "Training:   6%|▌         | 28/484 [00:01<00:13, 32.90it/s]\u001b[A\n",
            "Training:   7%|▋         | 32/484 [00:01<00:13, 33.49it/s]\u001b[A\n",
            "Training:   7%|▋         | 36/484 [00:01<00:12, 34.98it/s]\u001b[A\n",
            "Training:   8%|▊         | 40/484 [00:01<00:12, 36.12it/s]\u001b[A\n",
            "Training:   9%|▉         | 44/484 [00:01<00:12, 35.75it/s]\u001b[A\n",
            "Training:  10%|▉         | 48/484 [00:01<00:12, 35.63it/s]\u001b[A\n",
            "Training:  11%|█         | 52/484 [00:01<00:12, 35.89it/s]\u001b[A\n",
            "Training:  12%|█▏        | 56/484 [00:01<00:12, 35.17it/s]\u001b[A\n",
            "Training:  12%|█▏        | 60/484 [00:01<00:11, 35.76it/s]\u001b[A\n",
            "Training:  13%|█▎        | 64/484 [00:02<00:11, 36.43it/s]\u001b[A\n",
            "Training:  14%|█▍        | 68/484 [00:02<00:11, 36.22it/s]\u001b[A\n",
            "Training:  15%|█▍        | 72/484 [00:02<00:11, 36.21it/s]\u001b[A\n",
            "Training:  16%|█▌        | 76/484 [00:02<00:11, 36.16it/s]\u001b[A\n",
            "Training:  17%|█▋        | 80/484 [00:02<00:11, 35.43it/s]\u001b[A\n",
            "Training:  17%|█▋        | 84/484 [00:02<00:11, 35.64it/s]\u001b[A\n",
            "Training:  18%|█▊        | 88/484 [00:02<00:11, 35.90it/s]\u001b[A\n",
            "Training:  19%|█▉        | 92/484 [00:02<00:11, 35.40it/s]\u001b[A\n",
            "Training:  20%|█▉        | 96/484 [00:02<00:10, 35.92it/s]\u001b[A\n",
            "Training:  21%|██        | 101/484 [00:03<00:10, 37.39it/s]\u001b[A\n",
            "Training:  22%|██▏       | 105/484 [00:03<00:10, 37.22it/s]\u001b[A\n",
            "Training:  23%|██▎       | 109/484 [00:03<00:10, 36.22it/s]\u001b[A\n",
            "Training:  23%|██▎       | 113/484 [00:03<00:10, 36.24it/s]\u001b[A\n",
            "Training:  24%|██▍       | 117/484 [00:03<00:10, 35.62it/s]\u001b[A\n",
            "Training:  25%|██▌       | 121/484 [00:03<00:10, 36.11it/s]\u001b[A\n",
            "Training:  26%|██▌       | 125/484 [00:03<00:09, 36.43it/s]\u001b[A\n",
            "Training:  27%|██▋       | 129/484 [00:03<00:09, 36.35it/s]\u001b[A\n",
            "Training:  27%|██▋       | 133/484 [00:03<00:09, 36.90it/s]\u001b[A\n",
            "Training:  28%|██▊       | 137/484 [00:04<00:09, 36.90it/s]\u001b[A\n",
            "Training:  29%|██▉       | 141/484 [00:04<00:09, 36.90it/s]\u001b[A\n",
            "Training:  30%|██▉       | 145/484 [00:04<00:09, 36.81it/s]\u001b[A\n",
            "Training:  31%|███       | 149/484 [00:04<00:09, 37.13it/s]\u001b[A\n",
            "Training:  32%|███▏      | 153/484 [00:04<00:09, 36.55it/s]\u001b[A\n",
            "Training:  32%|███▏      | 157/484 [00:04<00:09, 35.15it/s]\u001b[A\n",
            "Training:  33%|███▎      | 161/484 [00:04<00:08, 36.15it/s]\u001b[A\n",
            "Training:  34%|███▍      | 165/484 [00:04<00:08, 35.96it/s]\u001b[A\n",
            "Training:  35%|███▍      | 169/484 [00:04<00:08, 35.27it/s]\u001b[A\n",
            "Training:  36%|███▌      | 173/484 [00:05<00:08, 35.36it/s]\u001b[A\n",
            "Training:  37%|███▋      | 177/484 [00:05<00:10, 28.25it/s]\u001b[A\n",
            "Training:  37%|███▋      | 181/484 [00:05<00:13, 22.89it/s]\u001b[A\n",
            "Training:  38%|███▊      | 184/484 [00:05<00:12, 24.23it/s]\u001b[A\n",
            "Training:  39%|███▉      | 188/484 [00:05<00:10, 27.29it/s]\u001b[A\n",
            "Training:  40%|███▉      | 192/484 [00:05<00:09, 29.66it/s]\u001b[A\n",
            "Training:  40%|████      | 196/484 [00:05<00:09, 29.90it/s]\u001b[A\n",
            "Training:  41%|████▏     | 200/484 [00:06<00:12, 22.00it/s]\u001b[A\n",
            "Training:  42%|████▏     | 203/484 [00:06<00:14, 18.74it/s]\u001b[A\n",
            "Training:  43%|████▎     | 207/484 [00:06<00:12, 22.06it/s]\u001b[A\n",
            "Training:  44%|████▎     | 211/484 [00:06<00:10, 25.34it/s]\u001b[A\n",
            "Training:  44%|████▍     | 215/484 [00:06<00:09, 27.59it/s]\u001b[A\n",
            "Training:  45%|████▌     | 219/484 [00:06<00:08, 30.03it/s]\u001b[A\n",
            "Training:  46%|████▌     | 223/484 [00:07<00:09, 27.90it/s]\u001b[A\n",
            "Training:  47%|████▋     | 227/484 [00:07<00:12, 19.90it/s]\u001b[A\n",
            "Training:  48%|████▊     | 230/484 [00:07<00:11, 21.46it/s]\u001b[A\n",
            "Training:  48%|████▊     | 234/484 [00:07<00:10, 24.34it/s]\u001b[A\n",
            "Training:  49%|████▉     | 238/484 [00:07<00:09, 26.39it/s]\u001b[A\n",
            "Training:  50%|█████     | 242/484 [00:07<00:08, 28.26it/s]\u001b[A\n",
            "Training:  51%|█████     | 246/484 [00:07<00:07, 30.06it/s]\u001b[A\n",
            "Training:  52%|█████▏    | 250/484 [00:08<00:07, 31.44it/s]\u001b[A\n",
            "Training:  52%|█████▏    | 254/484 [00:08<00:07, 32.72it/s]\u001b[A\n",
            "Training:  53%|█████▎    | 258/484 [00:08<00:06, 33.95it/s]\u001b[A\n",
            "Training:  54%|█████▍    | 262/484 [00:08<00:06, 34.94it/s]\u001b[A\n",
            "Training:  55%|█████▍    | 266/484 [00:08<00:06, 34.62it/s]\u001b[A\n",
            "Training:  56%|█████▌    | 270/484 [00:08<00:06, 33.65it/s]\u001b[A\n",
            "Training:  57%|█████▋    | 274/484 [00:08<00:06, 34.45it/s]\u001b[A\n",
            "Training:  57%|█████▋    | 278/484 [00:08<00:05, 35.81it/s]\u001b[A\n",
            "Training:  58%|█████▊    | 282/484 [00:08<00:05, 35.05it/s]\u001b[A\n",
            "Training:  59%|█████▉    | 286/484 [00:09<00:05, 35.31it/s]\u001b[A\n",
            "Training:  60%|█████▉    | 290/484 [00:09<00:05, 34.77it/s]\u001b[A\n",
            "Training:  61%|██████    | 294/484 [00:09<00:05, 35.35it/s]\u001b[A\n",
            "Training:  62%|██████▏   | 298/484 [00:09<00:05, 34.26it/s]\u001b[A\n",
            "Training:  62%|██████▏   | 302/484 [00:09<00:05, 33.15it/s]\u001b[A\n",
            "Training:  63%|██████▎   | 306/484 [00:09<00:05, 32.26it/s]\u001b[A\n",
            "Training:  64%|██████▍   | 310/484 [00:09<00:05, 32.53it/s]\u001b[A\n",
            "Training:  65%|██████▍   | 314/484 [00:09<00:04, 34.09it/s]\u001b[A\n",
            "Training:  66%|██████▌   | 319/484 [00:10<00:04, 35.53it/s]\u001b[A\n",
            "Training:  67%|██████▋   | 323/484 [00:10<00:04, 35.63it/s]\u001b[A\n",
            "Training:  68%|██████▊   | 328/484 [00:10<00:04, 37.22it/s]\u001b[A\n",
            "Training:  69%|██████▊   | 332/484 [00:10<00:04, 37.00it/s]\u001b[A\n",
            "Training:  69%|██████▉   | 336/484 [00:10<00:03, 37.73it/s]\u001b[A\n",
            "Training:  70%|███████   | 340/484 [00:10<00:03, 36.65it/s]\u001b[A\n",
            "Training:  71%|███████   | 344/484 [00:10<00:03, 36.60it/s]\u001b[A\n",
            "Training:  72%|███████▏  | 348/484 [00:10<00:03, 36.98it/s]\u001b[A\n",
            "Training:  73%|███████▎  | 352/484 [00:10<00:03, 37.43it/s]\u001b[A\n",
            "Training:  74%|███████▎  | 356/484 [00:11<00:03, 37.07it/s]\u001b[A\n",
            "Training:  74%|███████▍  | 360/484 [00:11<00:03, 37.23it/s]\u001b[A\n",
            "Training:  75%|███████▌  | 364/484 [00:11<00:03, 37.11it/s]\u001b[A\n",
            "Training:  76%|███████▌  | 368/484 [00:11<00:03, 35.78it/s]\u001b[A\n",
            "Training:  77%|███████▋  | 372/484 [00:11<00:03, 35.18it/s]\u001b[A\n",
            "Training:  78%|███████▊  | 376/484 [00:11<00:03, 34.70it/s]\u001b[A\n",
            "Training:  79%|███████▊  | 380/484 [00:11<00:02, 34.95it/s]\u001b[A\n",
            "Training:  79%|███████▉  | 384/484 [00:11<00:02, 35.56it/s]\u001b[A\n",
            "Training:  80%|████████  | 388/484 [00:11<00:02, 35.26it/s]\u001b[A\n",
            "Training:  81%|████████  | 392/484 [00:12<00:02, 35.40it/s]\u001b[A\n",
            "Training:  82%|████████▏ | 396/484 [00:12<00:02, 36.54it/s]\u001b[A\n",
            "Training:  83%|████████▎ | 400/484 [00:12<00:02, 35.97it/s]\u001b[A\n",
            "Training:  83%|████████▎ | 404/484 [00:12<00:02, 35.59it/s]\u001b[A\n",
            "Training:  84%|████████▍ | 408/484 [00:12<00:02, 35.80it/s]\u001b[A\n",
            "Training:  85%|████████▌ | 412/484 [00:12<00:02, 34.94it/s]\u001b[A\n",
            "Training:  86%|████████▌ | 416/484 [00:12<00:01, 34.87it/s]\u001b[A\n",
            "Training:  87%|████████▋ | 420/484 [00:12<00:01, 35.41it/s]\u001b[A\n",
            "Training:  88%|████████▊ | 424/484 [00:12<00:01, 35.46it/s]\u001b[A\n",
            "Training:  88%|████████▊ | 428/484 [00:13<00:01, 35.64it/s]\u001b[A\n",
            "Training:  89%|████████▉ | 432/484 [00:13<00:01, 35.00it/s]\u001b[A\n",
            "Training:  90%|█████████ | 436/484 [00:13<00:01, 35.29it/s]\u001b[A\n",
            "Training:  91%|█████████ | 440/484 [00:13<00:01, 33.94it/s]\u001b[A\n",
            "Training:  92%|█████████▏| 444/484 [00:13<00:01, 32.96it/s]\u001b[A\n",
            "Training:  93%|█████████▎| 448/484 [00:13<00:01, 31.87it/s]\u001b[A\n",
            "Training:  93%|█████████▎| 452/484 [00:13<00:00, 32.03it/s]\u001b[A\n",
            "Training:  94%|█████████▍| 456/484 [00:13<00:00, 33.08it/s]\u001b[A\n",
            "Training:  95%|█████████▌| 460/484 [00:14<00:00, 34.37it/s]\u001b[A\n",
            "Training:  96%|█████████▌| 464/484 [00:14<00:00, 35.43it/s]\u001b[A\n",
            "Training:  97%|█████████▋| 468/484 [00:14<00:00, 35.50it/s]\u001b[A\n",
            "Training:  98%|█████████▊| 472/484 [00:14<00:00, 35.94it/s]\u001b[A\n",
            "Training:  98%|█████████▊| 476/484 [00:14<00:00, 36.56it/s]\u001b[A\n",
            "Training: 100%|██████████| 484/484 [00:14<00:00, 32.73it/s]\n",
            "100%|██████████| 1/1 [00:17<00:00, 17.52s/it]\n"
          ]
        }
      ]
    }
  ]
}